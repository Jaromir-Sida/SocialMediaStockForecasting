{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Tokenization\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\jaromir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning steps:\n",
    "\n",
    "1. Get tweet_id\n",
    "1. Drop unnecessary columns - permalink, formated date \n",
    "1. Extract cashtags\n",
    "1. Extract emojis\n",
    "1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data - New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth',280)\n",
    "pd.set_option('display.html.use_mathjax', False)\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = r'c:\\Users\\jaromir\\OneDrive\\UoM\\100_Disertation\\02_SrcData\\04_CleanData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob(src_path+'\\*.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\jaromir\\\\OneDrive\\\\UoM\\\\100_Disertation\\\\02_SrcData\\\\04_CleanData\\\\stock_prices_20200805.pkl',\n",
       " 'c:\\\\Users\\\\jaromir\\\\OneDrive\\\\UoM\\\\100_Disertation\\\\02_SrcData\\\\04_CleanData\\\\tweets_20200826_110327.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in filenames:\n",
    "    if 'tweets' in file:\n",
    "        tweets = pd.read_pickle(file)\n",
    "    else:\n",
    "        stock_prices = pd.read_pickle(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = tweets.loc[:,['text','ticker']]\n",
    "df_rest = tweets.loc[:,~tweets.columns.isin(['text','ticker'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data - Existing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path_ex = r'c:\\Users\\jaromir\\OneDrive\\UoM\\100_Disertation\\02_SrcData\\05_PreProcessed'\n",
    "\n",
    "# search for available files\n",
    "filenames = glob(src_path_ex+'\\*.pkl')\n",
    "\n",
    "# load files\n",
    "# tweets = pd.read_pickle(filenames[0])\n",
    "#stock_prices = pd.read_pickle(filenames[1])\n",
    "\n",
    "#df_text = tweets.loc[:,['text','ticker','filtered_text','spacy_lemma','nltk_lemma']]\n",
    "#df_rest = tweets.loc[:,~tweets.columns.isin(['text','ticker','filtered_text','spacy_lemma','nltk_lemma'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract cashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change $ticker to #ticker so that it get tokenized together\n",
    "# make sure it is not greedy \n",
    "cashtag_finder = re.compile(r\"\\$[a-zA-Z]+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cashtags(document, filter_condition):\n",
    "    \"\"\"extracts cashtags from a tweets and return a strign separated by spaces\"\"\"\n",
    "    document = re.findall(filter_condition, document)\n",
    "    cashtags = ' '.join(document).upper()\n",
    "    return cashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cashtag_handle(df, sub_regex):\n",
    "    \"\"\"finds cashtags and moves them to a separate feature\"\"\"   \n",
    "    df.loc[:,'cashtags'] = df.loc[:,'text'].apply(find_cashtags, args=[sub_regex])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_text = cashtag_handle(df_text,cashtag_finder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_emojis(s):\n",
    "    return ''.join(c for c in s if c in emoji.UNICODE_EMOJI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_text['emoji'] = df_text.loc[:,'text'].apply(extract_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emoji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>191464</th>\n",
       "      <td>This is a big deal. $amzn. Amazonâ€™s ad biz-3.9 billion in revenueâ€”an increase of 44% YoY. . Market Realist</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91252</th>\n",
       "      <td>Iâ€™m long $AAPL (largest % holding) $MSFT, $SBUX $T. Have been adding to my positions over the last month. Also added $TMUS $MA and $V. Have been watching $HD and have some hindsight bias about missing it at $201 a few weeks ago.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380991</th>\n",
       "      <td>Day three of rotation. $MSFT calls likely to heat up tomorrow as Rotatavirus curve flattens. Ridiculous.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286276</th>\n",
       "      <td>Cut losses on $GILD</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301890</th>\n",
       "      <td>Johnson &amp; Johnson $JNJ COO Michael E. Sneed Sells 58,128 Shares http://zpr.io/tKJCZ</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                        text  \\\n",
       "191464                                                                                                                           This is a big deal. $amzn. Amazonâ€™s ad biz-3.9 billion in revenueâ€”an increase of 44% YoY. . Market Realist    \n",
       "91252   Iâ€™m long $AAPL (largest % holding) $MSFT, $SBUX $T. Have been adding to my positions over the last month. Also added $TMUS $MA and $V. Have been watching $HD and have some hindsight bias about missing it at $201 a few weeks ago.   \n",
       "380991                                                                                                                              Day three of rotation. $MSFT calls likely to heat up tomorrow as Rotatavirus curve flattens. Ridiculous.   \n",
       "286276                                                                                                                                                                                                                  Cut losses on $GILD    \n",
       "301890                                                                                                                                                   Johnson & Johnson $JNJ COO Michael E. Sneed Sells 58,128 Shares http://zpr.io/tKJCZ   \n",
       "\n",
       "       emoji  \n",
       "191464        \n",
       "91252         \n",
       "380991        \n",
       "286276        \n",
       "301890        "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text[['text','emoji']].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$AAPL $MSFT $JPM - Apple, Microsoft top Dow 2019 standings; Walgreens wobbles to the bottom https://seekingalpha.com/news/3529009-apple-microsoft-top-dow-2019-standings-walgreens-wobbles-to-bottom?source=tweet \n",
      "\n",
      "$AAPL $MSFT $JPM - Apple, Microsoft top Dow 2019 standings; Walgreens wobbles to the bottom https://seekingalpha.com/news/3529009-apple-microsoft-top-dow-2019-standings-walgreens-wobbles-to-bottom?source=tweet\n"
     ]
    }
   ],
   "source": [
    "# replace a + b \n",
    "plus_filter = re.compile(r\"\\s\\+\\s\")\n",
    "\n",
    "idx = 300 \n",
    "print(df_text.loc[idx,'text'],\"\\n\")\n",
    "print(re.sub(plus_filter, \"plus\",df_text.loc[idx,'text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$AMZN Verizon joins Amazon and Global Optimism in signing The Climate Pledge https://www.otcdynamics.com/amzn-verizon-joins-amazon-and-global-optimism-in-signing-the-climate-pledge/?utm_campaign=twitter&amp;utm_medium=twitter&amp;utm_source=twitter \n",
      "\n",
      "$AMZN Verizon joins Amazon and Global Optimism in signing The Climate Pledge https://www.otcdynamics.com/amzn-verizon-joins-amazon-and-global-optimism-in-signing-the-climate-pledge/?utm_campaign=twitter&amp;utm_medium=twitter&amp;utm_source=twitter\n"
     ]
    }
   ],
   "source": [
    "# replace 4+\n",
    "four_plus_filter = re.compile(r\"\\d+\\+\")\n",
    "\n",
    "idx = 217169\n",
    "print(df_text.loc[idx,'text'],\"\\n\")\n",
    "print(re.sub(four_plus_filter, \"more than\",df_text.loc[idx,'text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forever #mood $X $SPY $QQQ $AAPL  \n",
      "\n",
      "Forever #mood $X $SPY $QQQ $AAPL \n"
     ]
    }
   ],
   "source": [
    "# replace  -70%\n",
    "minus_filter = re.compile(r\"\\s\\-\\d+%*\")\n",
    "\n",
    "idx = 63774\n",
    "print(df_text.loc[idx,'text'],\"\\n\")\n",
    "print(re.sub(minus_filter, \"\",df_text.loc[idx,'text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$AAPL has cored me somewhat today, my SHORT is underwater, still holding as the premise has NOT changed, out SHORTS on $NFLX, $SAM, $BA, $OLED, $AMD are more than offsetting $AAPL losses by 3-fold today \n",
      "\n",
      "$AAPL has cored me somewhat today, my SHORT is underwater, still holding as the premise has NOT changed, out SHORTS on $NFLX, $SAM, $BA, $OLED, $AMD are more than offsetting $AAPL losses by 3-fold today\n"
     ]
    }
   ],
   "source": [
    "# replace  %\n",
    "percent_filter = re.compile(r\"%+\")\n",
    "\n",
    "idx = 19011\n",
    "print(df_text.loc[idx,'text'],\"\\n\")\n",
    "print(re.sub(percent_filter, \"\",df_text.loc[idx,'text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "renamed_strings = {'plus': [plus_filter,'plus'],\n",
    "                   'four_plus' : [four_plus_filter,'more than'],\n",
    "                   'minus' : [minus_filter,'minus'],\n",
    "                   'percent' : [percent_filter,'percentage']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_strings(document, filter_condition, replacement_string):\n",
    "    \"\"\"replace given regEx string with a space\"\"\"\n",
    "    document = re.sub(filter_condition, replacement_string, document)\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_strings_in_documents(df, filters):\n",
    "    \"\"\"filter results for all documents\"\"\"\n",
    "    for char_filter in filters.keys():       \n",
    "        df.loc[:,'filtered_text'] = df.loc[:,'text'].apply(rename_strings, args=filters[char_filter])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_text = replace_strings_in_documents(df_text, renamed_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>filtered_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>326946</th>\n",
       "      <td>Lol...but would help my $MCD puts</td>\n",
       "      <td>Lol...but would help my $MCD puts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261569</th>\n",
       "      <td>â€¢ðŸ’¡ Bulls &amp;amp; Bears Make Money Pigs Get Slaughtered. ðŸ“ˆ Long - Focus on Reltve strngth into any morning weakness into 3312 ðŸ“‰ Short - Watch internals at 3345 4short add $spy $aapl $nvda $amzn $uso $bynd $ba $bmy $dis $tsla $wmt $xom $biib $gild $nflx $gold $ccl $mcd $xle $shak</td>\n",
       "      <td>â€¢ðŸ’¡ Bulls &amp;amp; Bears Make Money Pigs Get Slaughtered. ðŸ“ˆ Long - Focus on Reltve strngth into any morning weakness into 3312 ðŸ“‰ Short - Watch internals at 3345 4short add $spy $aapl $nvda $amzn $uso $bynd $ba $bmy $dis $tsla $wmt $xom $biib $gild $nflx $gold $ccl $mcd $xle $shak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100813</th>\n",
       "      <td>Dow Jones Stocks To Buy And Watch In May 2020; Apple, Microsoft Approach New Buy Points $JNJ $AAPL $INTC $HD $MSFT</td>\n",
       "      <td>Dow Jones Stocks To Buy And Watch In May 2020; Apple, Microsoft Approach New Buy Points $JNJ $AAPL $INTC $HD $MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224559</th>\n",
       "      <td>Top Stock Trades for Thursday $AMZN $APT $LAKE $RAD</td>\n",
       "      <td>Top Stock Trades for Thursday $AMZN $APT $LAKE $RAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116582</th>\n",
       "      <td>iâ€™d say this is the chop/value zone coin flip how we move from here but iâ€™d say down is more likely. if we do letâ€™s see how far we go $SPY $AAPL</td>\n",
       "      <td>iâ€™d say this is the chop/value zone coin flip how we move from here but iâ€™d say down is more likely. if we do letâ€™s see how far we go $SPY $AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                        text  \\\n",
       "326946                                                                                                                                                                                                                                                    Lol...but would help my $MCD puts    \n",
       "261569  â€¢ðŸ’¡ Bulls &amp; Bears Make Money Pigs Get Slaughtered. ðŸ“ˆ Long - Focus on Reltve strngth into any morning weakness into 3312 ðŸ“‰ Short - Watch internals at 3345 4short add $spy $aapl $nvda $amzn $uso $bynd $ba $bmy $dis $tsla $wmt $xom $biib $gild $nflx $gold $ccl $mcd $xle $shak   \n",
       "100813                                                                                                                                                                    Dow Jones Stocks To Buy And Watch In May 2020; Apple, Microsoft Approach New Buy Points $JNJ $AAPL $INTC $HD $MSFT   \n",
       "224559                                                                                                                                                                                                                                   Top Stock Trades for Thursday $AMZN $APT $LAKE $RAD   \n",
       "116582                                                                                                                                     iâ€™d say this is the chop/value zone coin flip how we move from here but iâ€™d say down is more likely. if we do letâ€™s see how far we go $SPY $AAPL    \n",
       "\n",
       "                                                                                                                                                                                                                                                                               filtered_text  \n",
       "326946                                                                                                                                                                                                                                                    Lol...but would help my $MCD puts   \n",
       "261569  â€¢ðŸ’¡ Bulls &amp; Bears Make Money Pigs Get Slaughtered. ðŸ“ˆ Long - Focus on Reltve strngth into any morning weakness into 3312 ðŸ“‰ Short - Watch internals at 3345 4short add $spy $aapl $nvda $amzn $uso $bynd $ba $bmy $dis $tsla $wmt $xom $biib $gild $nflx $gold $ccl $mcd $xle $shak  \n",
       "100813                                                                                                                                                                    Dow Jones Stocks To Buy And Watch In May 2020; Apple, Microsoft Approach New Buy Points $JNJ $AAPL $INTC $HD $MSFT  \n",
       "224559                                                                                                                                                                                                                                   Top Stock Trades for Thursday $AMZN $APT $LAKE $RAD  \n",
       "116582                                                                                                                                     iâ€™d say this is the chop/value zone coin flip how we move from here but iâ€™d say down is more likely. if we do letâ€™s see how far we go $SPY $AAPL   "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text.loc[:,['text','filtered_text']].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove emojis\n",
    "def remove_emojis(text):\n",
    "    return ''.join(token for token in text if token not in emoji.UNICODE_EMOJI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_text.loc[:,'filtered_text'] = df_text.loc[:,'filtered_text'].apply(remove_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple and Microsoft $AAPL $MSFT dominated S&amp;P 500 this past decade:\n",
      "Apple and Microsoft $AAPL $MSFT dominated S&amp;P 500 this past decade:\n"
     ]
    }
   ],
   "source": [
    "# remove urls\n",
    "url_filter = re.compile(r\"www.[\\w\\d]+.\\w+|http://\\S+|https://\\S+\")\n",
    "print(df_text.loc[5,'text'])\n",
    "print(re.sub(url_filter, \"\",df_text.loc[5,'text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019 Jan 2nd (22:30gmt) $JPY flash crash backdrop: - risk aversion sentiment on political risks - material shift in $AUD short to long positioning in prior quarter (build of stops) - $AAPL downgrade amid fears of China slowdown - China #Caixin PMI miss at 48.3 approx 3 year low \n",
      "\n",
      "2019 Jan 2nd (22:30gmt) $JPY flash crash backdrop: - risk aversion sentiment on political risks - material shift in $AUD short to long positioning in prior quarter (build of stops) - $AAPL downgrade amid fears of China slowdown - China  PMI miss at 48.3 approx 3 year low\n"
     ]
    }
   ],
   "source": [
    "# remove hashtags\n",
    "hashtag_filter = re.compile(r\"#\\w+\")\n",
    "print(df_text.loc[0,'text'],\"\\n\")\n",
    "print(re.sub(hashtag_filter, \"\",df_text.loc[0,'text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple and Microsoft $AAPL $MSFT dominated S&amp;P 500 this past decade: \n",
      "\n",
      "Apple and Microsoft $AAPL $MSFT dominated S&amp;P 500 this past decade:\n"
     ]
    }
   ],
   "source": [
    "# remove mentions\n",
    "mentions_filter = re.compile(r\"@\\w+\")\n",
    "print(df_text.loc[5,'text'],\"\\n\")\n",
    "print(re.sub(mentions_filter, \"\",df_text.loc[5,'text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019 Jan 2nd (22:30gmt) $JPY flash crash backdrop: - risk aversion sentiment on political risks - material shift in $AUD short to long positioning in prior quarter (build of stops) - $AAPL downgrade amid fears of China slowdown - China #Caixin PMI miss at 48.3 approx 3 year low \n",
      "\n",
      "2019 Jan 2nd (22:30gmt)  flash crash backdrop: - risk aversion sentiment on political risks - material shift in  short to long positioning in prior quarter (build of stops) -  downgrade amid fears of China slowdown - China #Caixin PMI miss at 48.3 approx 3 year low\n"
     ]
    }
   ],
   "source": [
    "# remove cashtags\n",
    "cashtag_filter = re.compile(r\"\\$\\w+\")\n",
    "print(df_text.loc[0,'text'],\"\\n\")\n",
    "print(re.sub(cashtag_filter, \"\",df_text.loc[0,'text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Its amazning how much more money $AAPL makes than $AMZN (3-6x) but they roughly have the same market cap. \n",
      "\n",
      "Its amazning how much more money $AAPL makes than $AMZN (3-6x) but they roughly have the same market cap.\n"
     ]
    }
   ],
   "source": [
    "# amount & date filter\n",
    "amount_filter = re.compile(r\"\"\"\\d+[kKmM]+           # 4k, 5M\n",
    "                              |\\d+B                 # 1B\n",
    "                              |\\d+c                 # 1c\n",
    "                              |\\d+bn                # 1bn\n",
    "                              |\\d+BN                # 1BN\n",
    "                              |\\d+Bn                # 1Bn\n",
    "                              |\\d+mil               # 1mil\n",
    "                              |\\d+st                # 1st\n",
    "                              |\\d+nd                # 2nd\n",
    "                              |\\d+rd                # 3rd\n",
    "                              |\\d+th                # 4th\n",
    "                              |\\d+y                 # 25y\n",
    "                                \"\"\",\n",
    "                                re.VERBOSE)\n",
    "idx = 83543\n",
    "print(df_text.loc[idx,'text'],\"\\n\")\n",
    "print(re.sub(amount_filter, \"\",df_text.loc[idx,'text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Beginnerâ€™s Guide to Stock Investing. On Amazon. Link: https://www.amazon.com/Beginners-Guide-Stock-Investing-Getting-ebook/dp/B07FTXYXKJ/ref=sr_1_1?ie=UTF8&amp;qid=1532939123&amp;sr=8-1&amp;keywords=rocco+capici $FB $GOOGL $JPM $BAC $WFC $AAPL $PM $PG $GE $HON $JNJ $CSCO $MSFT $INTC $TWTR $TSLA $V $DIS $UNH $VZ $KHC $SLB $XOM $ES_F $GC_F $NQ_F $CL_F $ZB_F $TLT $MET $PNC $CTL $LMT $WMT $TGT $DLTR $AMZN \n",
      "\n",
      "A Beginnerâ€™s Guide to Stock Investing On Amazon Link httpswwwamazoncomBeginnersGuideStockInvestingGettingebookdpBFTXYXKJrefsr__ieUTFampqidampsrampkeywordsroccocapici FB GOOGL JPM BAC WFC AAPL PM PG GE HON JNJ CSCO MSFT INTC TWTR TSLA V DIS UNH VZ KHC SLB XOM ES_F GC_F NQ_F CL_F ZB_F TLT MET PNC CTL LMT WMT TGT DLTR AMZN\n"
     ]
    }
   ],
   "source": [
    "# remove non-alphanumeric characters\n",
    "schar_filter = re.compile(r\"[0-9%&+?!$,;=:.(â€¦)\\\"'/{}â€œ-]+\")\n",
    "idx = 29524\n",
    "print(df_text.loc[idx,'text'],\"\\n\")\n",
    "print(re.sub(schar_filter, \"\",df_text.loc[idx,'text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = [url_filter, hashtag_filter, mentions_filter, cashtag_filter, amount_filter, schar_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_results(document, filter_condition):\n",
    "    \"\"\"replace given regEx string with a space\"\"\"\n",
    "    document = re.sub(filter_condition, \" \", document)\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_documents(df, filters):\n",
    "    \"\"\"filter results for all documents\"\"\"\n",
    "    for char_filter in filters:       \n",
    "        df.loc[:,'filtered_text'] = df.loc[:,'filtered_text'].apply(filter_results, args=[char_filter])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_text = filter_documents(df_text, filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>filtered_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>185546</th>\n",
       "      <td>$SPY $NASDAQ $DJIA Don't short yet bears its not time, wait until the $QQQs finish rallying and you see weird shit like $AMZN at 3k and $MSFT at 250. When shit gets really weird is when you pull out the shorts. Pretty clear where they are going to go and hide.</td>\n",
       "      <td>Don t short yet bears its not time  wait until the   finish rallying and you see weird shit like   at   and   at   When shit gets really weird is when you pull out the shorts  Pretty clear where they are going to go and hide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182036</th>\n",
       "      <td>You wonder why #StockMarket is rising despite our struggling #economy? #CoronaCrisis is shifting power to the digital world - the FANG companies: $FB, $AMZN, $NFLX, $GOOG, $MSFT, $AAPL Now look at their weighting in the S&amp;amp;P 500 and you will understand. #stocks #OilCrash #...</td>\n",
       "      <td>You wonder why   is rising despite our struggling      is shifting power to the digital world   the FANG companies                   Now look at their weighting in the S amp P   and you will understand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223274</th>\n",
       "      <td>Job listings out of Amazon $AMZN are pointing towards the company adding live TV to Amazon Prime to help differentiate the service from competitors like Netflix $NFLX, Disney Plus $DIS, &amp;amp; HBO $T. It's not exactly clear what type of live content $AMZN is going after.</td>\n",
       "      <td>Job listings out of Amazon   are pointing towards the company adding live TV to Amazon Prime to help differentiate the service from competitors like Netflix    Disney Plus     amp  HBO    It s not exactly clear what type of live content   is going after</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127017</th>\n",
       "      <td>Dr. Henry Balogun Announces Release of New Book, \"Enemy of the Human Race\" $AMZN $BNED $AAPL</td>\n",
       "      <td>Dr  Henry Balogun Announces Release of New Book   Enemy of the Human Race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136498</th>\n",
       "      <td>ACTIVE TRADERS Try one of these FREE trading guides: http://ow.ly/7t5E30qbuCV $NFLX $TSLA $AAPL $SBUX $GS $FB $AMZN $GOOGL $NVDA</td>\n",
       "      <td>ACTIVE TRADERS Try one of these FREE trading guides</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                           text  \\\n",
       "185546                     $SPY $NASDAQ $DJIA Don't short yet bears its not time, wait until the $QQQs finish rallying and you see weird shit like $AMZN at 3k and $MSFT at 250. When shit gets really weird is when you pull out the shorts. Pretty clear where they are going to go and hide.   \n",
       "182036  You wonder why #StockMarket is rising despite our struggling #economy? #CoronaCrisis is shifting power to the digital world - the FANG companies: $FB, $AMZN, $NFLX, $GOOG, $MSFT, $AAPL Now look at their weighting in the S&amp;P 500 and you will understand. #stocks #OilCrash #...   \n",
       "223274          Job listings out of Amazon $AMZN are pointing towards the company adding live TV to Amazon Prime to help differentiate the service from competitors like Netflix $NFLX, Disney Plus $DIS, &amp; HBO $T. It's not exactly clear what type of live content $AMZN is going after.    \n",
       "127017                                                                                                                                                                                             Dr. Henry Balogun Announces Release of New Book, \"Enemy of the Human Race\" $AMZN $BNED $AAPL   \n",
       "136498                                                                                                                                                         ACTIVE TRADERS Try one of these FREE trading guides: http://ow.ly/7t5E30qbuCV $NFLX $TSLA $AAPL $SBUX $GS $FB $AMZN $GOOGL $NVDA   \n",
       "\n",
       "                                                                                                                                                                                                                                                          filtered_text  \n",
       "185546                                Don t short yet bears its not time  wait until the   finish rallying and you see weird shit like   at   and   at   When shit gets really weird is when you pull out the shorts  Pretty clear where they are going to go and hide   \n",
       "182036                                                 You wonder why   is rising despite our struggling      is shifting power to the digital world   the FANG companies                   Now look at their weighting in the S amp P   and you will understand         \n",
       "223274  Job listings out of Amazon   are pointing towards the company adding live TV to Amazon Prime to help differentiate the service from competitors like Netflix    Disney Plus     amp  HBO    It s not exactly clear what type of live content   is going after    \n",
       "127017                                                                                                                                                                                 Dr  Henry Balogun Announces Release of New Book   Enemy of the Human Race         \n",
       "136498                                                                                                                                                                                         ACTIVE TRADERS Try one of these FREE trading guides                       "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text[['text','filtered_text']].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatize & remove stopwords and keep only alphanumeric lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy - token + stopwords + lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess text\n",
    "stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "def preprocess_pos(text):\n",
    "    # Create Doc object\n",
    "    doc = nlp(text, disable=['ner', 'parser'])\n",
    "    # Generate lemmas\n",
    "    lemmas = [(token.lemma_ , token.tag_) for token in doc]\n",
    "    # Remove stopwords and non-alphabetic characters\n",
    "    a_lemmas = [(lemma[0], get_wordnet_pos(lemma[1])) for lemma in lemmas \n",
    "            if lemma[0] not in stopwords and lemma[0] != '-PRON-' and lemma[1] != '_SP']\n",
    "    \n",
    "    return a_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Apply preprocess to ted['transcript']\n",
    "df_text.loc[:,'spacy_lemma_pos'] = df_text.loc[:,'filtered_text'].apply(preprocess_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lemma(list_of_tags):\n",
    "    return [lemma[0] for lemma in list_of_tags] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Apply preprocess to ted['transcript']\n",
    "df_text.loc[:,'spacy_lemma'] = df_text.loc[:,'spacy_lemma_pos'].apply(extract_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>filtered_text</th>\n",
       "      <th>spacy_lemma_pos</th>\n",
       "      <th>spacy_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>318190</th>\n",
       "      <td>Marriott International shares are trading lower after the company reported worse-than-expected Q1 EPS results. 7:30:05am Related Tickers: $MAR</td>\n",
       "      <td>Marriott International shares are trading lower after the company reported worse than expected Q  EPS results   am Related Tickers</td>\n",
       "      <td>[(Marriott, n), (International, n), (share, n), (trade, v), (low, a), (company, n), (report, v), (bad, a), (expect, v), (Q, n), (EPS, n), (result, n), (relate, v), (Tickers, n)]</td>\n",
       "      <td>[Marriott, International, share, trade, low, company, report, bad, expect, Q, EPS, result, relate, Tickers]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234909</th>\n",
       "      <td>$EGO chart; Snapped itâ€™s downtrend line. #gold/#silver $TSLA $UBER $NIO $MU $NVDA $INTC $LYFT $XLNX $BIDU $AAPL $IRBT $DIS $PTON $AMD $BILL $M $FISV $NFLX $BABA $LK $Z $CHGG $CMG $SNAP $FB $BYND $LYFT $LULU $DT $EA $NEM $ROKU $RVMD $WDAY $PLUG $BE $FCEL $SPCE $ZM $BLDP</td>\n",
       "      <td>chart  Snapped itâ€™s downtrend line</td>\n",
       "      <td>[(chart, n), (snap, v), (â€™, v), (downtrend, n), (line, n)]</td>\n",
       "      <td>[chart, snap, â€™, downtrend, line]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203408</th>\n",
       "      <td>Let's end the day with another BIGMONEY winner just getting started ... $SQ 79C already hit 3.40 from 1.67 (&amp;gt;2X or 100% so far) ðŸ‘ŠðŸ¤‘ Email: optionsmaster@hotmail.com to subscribe. $AAPL $AMZN $BABA $BIDU $BYND $GOOGL $NFLX $NVDA $SPX $TSLA $SHOP</td>\n",
       "      <td>Let s end the day with another BIGMONEY winner just getting started      C already hit   from    gt X or  percentage so far   Email  optionsmaster  com to subscribe</td>\n",
       "      <td>[(let, v), (s, ), (end, v), (day, n), (BIGMONEY, n), (winner, n), (start, v), (C, n), (hit, v), (gt, ), (X, n), (percentage, n), (far, r), (Email, n), (optionsmaster, n), (com, n), (subscribe, v)]</td>\n",
       "      <td>[let, s, end, day, BIGMONEY, winner, start, C, hit, gt, X, percentage, far, Email, optionsmaster, com, subscribe]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134738</th>\n",
       "      <td>$AMZN Market Chatter: http://Amazon.com Files Trademark Applications for 'Amazon Pharmacy' in Canada, UK, Australia 1/21/20, 2:52 PM</td>\n",
       "      <td>Market Chatter    Files Trademark Applications for  Amazon Pharmacy  in Canada  UK  Australia     PM</td>\n",
       "      <td>[(Market, n), (Chatter, n), (Files, n), (Trademark, n), (Applications, n), (Amazon, n), (Pharmacy, n), (Canada, n), (UK, n), (Australia, n), (pm, n)]</td>\n",
       "      <td>[Market, Chatter, Files, Trademark, Applications, Amazon, Pharmacy, Canada, UK, Australia, pm]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9638</th>\n",
       "      <td>Live stream Tonight 9:30pm EST Canada i explain how I lead my group to massive gains In both $AAPL and $TSLA also I talk about $COST and $AMD $GOOGL, all of dec into this jan month it has been back to back wins, come and ask questions also I talk about the $SPY and the market</td>\n",
       "      <td>Live stream Tonight  pm EST Canada i explain how I lead my group to massive gains In both   and   also I talk about   and      all of dec into this jan month it has been back to back wins  come and ask questions also I talk about the   and the market</td>\n",
       "      <td>[(live, a), (stream, n), (tonight, n), (pm, n), (EST, n), (Canada, n), (explain, v), (lead, v), (group, n), (massive, a), (gain, n), (talk, v), (dec, n), (jan, n), (month, n), (win, n), (come, v), (ask, v), (question, n), (talk, v), (market, n)]</td>\n",
       "      <td>[live, stream, tonight, pm, EST, Canada, explain, lead, group, massive, gain, talk, dec, jan, month, win, come, ask, question, talk, market]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                        text  \\\n",
       "318190                                                                                                                                        Marriott International shares are trading lower after the company reported worse-than-expected Q1 EPS results. 7:30:05am Related Tickers: $MAR   \n",
       "234909         $EGO chart; Snapped itâ€™s downtrend line. #gold/#silver $TSLA $UBER $NIO $MU $NVDA $INTC $LYFT $XLNX $BIDU $AAPL $IRBT $DIS $PTON $AMD $BILL $M $FISV $NFLX $BABA $LK $Z $CHGG $CMG $SNAP $FB $BYND $LYFT $LULU $DT $EA $NEM $ROKU $RVMD $WDAY $PLUG $BE $FCEL $SPCE $ZM $BLDP   \n",
       "203408                                Let's end the day with another BIGMONEY winner just getting started ... $SQ 79C already hit 3.40 from 1.67 (&gt;2X or 100% so far) ðŸ‘ŠðŸ¤‘ Email: optionsmaster@hotmail.com to subscribe. $AAPL $AMZN $BABA $BIDU $BYND $GOOGL $NFLX $NVDA $SPX $TSLA $SHOP   \n",
       "134738                                                                                                                                                  $AMZN Market Chatter: http://Amazon.com Files Trademark Applications for 'Amazon Pharmacy' in Canada, UK, Australia 1/21/20, 2:52 PM   \n",
       "9638    Live stream Tonight 9:30pm EST Canada i explain how I lead my group to massive gains In both $AAPL and $TSLA also I talk about $COST and $AMD $GOOGL, all of dec into this jan month it has been back to back wins, come and ask questions also I talk about the $SPY and the market   \n",
       "\n",
       "                                                                                                                                                                                                                                                     filtered_text  \\\n",
       "318190                                                                                                                       Marriott International shares are trading lower after the company reported worse than expected Q  EPS results   am Related Tickers      \n",
       "234909                                                                                                                                     chart  Snapped itâ€™s downtrend line                                                                                        \n",
       "203408                                                                 Let s end the day with another BIGMONEY winner just getting started      C already hit   from    gt X or  percentage so far   Email  optionsmaster  com to subscribe                          \n",
       "134738                                                                                                                                                        Market Chatter    Files Trademark Applications for  Amazon Pharmacy  in Canada  UK  Australia     PM   \n",
       "9638    Live stream Tonight  pm EST Canada i explain how I lead my group to massive gains In both   and   also I talk about   and      all of dec into this jan month it has been back to back wins  come and ask questions also I talk about the   and the market   \n",
       "\n",
       "                                                                                                                                                                                                                                              spacy_lemma_pos  \\\n",
       "318190                                                                      [(Marriott, n), (International, n), (share, n), (trade, v), (low, a), (company, n), (report, v), (bad, a), (expect, v), (Q, n), (EPS, n), (result, n), (relate, v), (Tickers, n)]   \n",
       "234909                                                                                                                                                                                             [(chart, n), (snap, v), (â€™, v), (downtrend, n), (line, n)]   \n",
       "203408                                                   [(let, v), (s, ), (end, v), (day, n), (BIGMONEY, n), (winner, n), (start, v), (C, n), (hit, v), (gt, ), (X, n), (percentage, n), (far, r), (Email, n), (optionsmaster, n), (com, n), (subscribe, v)]   \n",
       "134738                                                                                                  [(Market, n), (Chatter, n), (Files, n), (Trademark, n), (Applications, n), (Amazon, n), (Pharmacy, n), (Canada, n), (UK, n), (Australia, n), (pm, n)]   \n",
       "9638    [(live, a), (stream, n), (tonight, n), (pm, n), (EST, n), (Canada, n), (explain, v), (lead, v), (group, n), (massive, a), (gain, n), (talk, v), (dec, n), (jan, n), (month, n), (win, n), (come, v), (ask, v), (question, n), (talk, v), (market, n)]   \n",
       "\n",
       "                                                                                                                                         spacy_lemma  \n",
       "318190                                   [Marriott, International, share, trade, low, company, report, bad, expect, Q, EPS, result, relate, Tickers]  \n",
       "234909                                                                                                             [chart, snap, â€™, downtrend, line]  \n",
       "203408                             [let, s, end, day, BIGMONEY, winner, start, C, hit, gt, X, percentage, far, Email, optionsmaster, com, subscribe]  \n",
       "134738                                                [Market, Chatter, Files, Trademark, Applications, Amazon, Pharmacy, Canada, UK, Australia, pm]  \n",
       "9638    [live, stream, tonight, pm, EST, Canada, explain, lead, group, massive, gain, talk, dec, jan, month, win, come, ask, question, talk, market]  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text[['text','filtered_text','spacy_lemma_pos','spacy_lemma']].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK token + stopwords + pos + lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 38.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Word Tokenization\n",
    "tokenizer = TweetTokenizer( preserve_case=True, reduce_len=False)\n",
    "df_text.loc[:,'nltk_lemma'] = df_text.filtered_text.apply(lambda x: tokenizer.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of stop words \n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "def remove_stopwords(list_of_words):\n",
    "    \"\"\" removes stopwords \"\"\"\n",
    "    no_stopwords = [t for t in list_of_words if t not in cachedStopWords]\n",
    "    return no_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_pos_tag(list_of_words):\n",
    "    return nltk.pos_tag(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_words(list_of_words):\n",
    "    # initialize a lemmatizer object\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    # initiate an empty container for lemmas\n",
    "    lemmatized_words_pos = []\n",
    "    # remove stopwords\n",
    "    list_of_words_ns = remove_stopwords(list_of_words)\n",
    "    # process a document by assigning pos tag\n",
    "    list_of_words_ns_pos = do_pos_tag(list_of_words_ns)\n",
    "    # iterate through the list of words flagged with pos and lemmatized accordingly\n",
    "    for word_tup in list_of_words_ns_pos:\n",
    "        current_pos = get_wordnet_pos(word_tup[1])\n",
    "        if current_pos == '': # not all pos tags have impact on lemmatization, all whuch dont have '' tag\n",
    "            lemmatized_words_pos.append((wordnet_lemmatizer.lemmatize(word_tup[0]), current_pos))\n",
    "        else:\n",
    "            lemmatized_words_pos.append((wordnet_lemmatizer.lemmatize(word_tup[0],current_pos), current_pos))\n",
    "    return lemmatized_words_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_text.loc[:,'nltk_lemma_pos'] = df_text.loc[:,'nltk_lemma'].apply(lemmatize_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Apply preprocess to ted['transcript']\n",
    "df_text.loc[:,'nltk_lemma'] = df_text.loc[:,'nltk_lemma_pos'].apply(extract_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>nltk_lemma_pos</th>\n",
       "      <th>nltk_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145314</th>\n",
       "      <td>@jimcramer Action member just wondering what Jimmy Chill thought of the strength in $AMZN shares Friday held up great in a red tape. Sign of things to come?</td>\n",
       "      <td>[(Action, n), (member, n), (wonder, v), (Jimmy, n), (Chill, n), (think, v), (strength, n), (share, n), (Friday, n), (hold, v), (great, a), (red, a), (tape, n), (Sign, n), (thing, n), (come, v)]</td>\n",
       "      <td>[Action, member, wonder, Jimmy, Chill, think, strength, share, Friday, hold, great, red, tape, Sign, thing, come]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214230</th>\n",
       "      <td>\"#Amazon's quest to grow its real estate footprint and resolve the enduring last-mile delivery problem may lead it to the most troubled corner of retail real estate â€” the department store.\" An $AMZN-$JCP $JCPNQ deal could reinvent retail real estate https://www.spglobal.com/m...</td>\n",
       "      <td>[(quest, a), (grow, a), (real, a), (estate, n), (footprint, n), (resolve, n), (endure, v), (last, a), (mile, a), (delivery, n), (problem, n), (may, ), (lead, v), (troubled, a), (corner, n), (retail, a), (real, a), (estate, n), (â€”, n), (department, n), (store, n), (An, ), (dea...</td>\n",
       "      <td>[quest, grow, real, estate, footprint, resolve, endure, last, mile, delivery, problem, may, lead, troubled, corner, retail, real, estate, â€”, department, store, An, deal, could, reinvent, retail, real, estate]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157712</th>\n",
       "      <td>$ROKU market up 500 pts but roku is down. so what happens if we have one of those lunchtime fades? watching to see if we have a sudden air pocket. $TSLA $NFLX $UNH $AMZN $GOOGL $SPY</td>\n",
       "      <td>[(market, n), (pt, n), (roku, v), (happen, v), (one, ), (lunchtime, n), (fade, v), (watch, v), (see, v), (sudden, a), (air, n), (pocket, n)]</td>\n",
       "      <td>[market, pt, roku, happen, one, lunchtime, fade, watch, see, sudden, air, pocket]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80012</th>\n",
       "      <td>Join @RobinhoodApp and we'll both get a stock like $AAPL, $F, or $S for free. Make sure to use my link.</td>\n",
       "      <td>[(Join, n), (get, v), (stock, n), (like, ), (free, a), (Make, n), (sure, n), (use, n), (link, n)]</td>\n",
       "      <td>[Join, get, stock, like, free, Make, sure, use, link]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45997</th>\n",
       "      <td>$SPY $AAPL $MSFT $TLT Cash is trash</td>\n",
       "      <td>[(Cash, n), (trash, n)]</td>\n",
       "      <td>[Cash, trash]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                           text  \\\n",
       "145314                                                                                                                             @jimcramer Action member just wondering what Jimmy Chill thought of the strength in $AMZN shares Friday held up great in a red tape. Sign of things to come?   \n",
       "214230  \"#Amazon's quest to grow its real estate footprint and resolve the enduring last-mile delivery problem may lead it to the most troubled corner of retail real estate â€” the department store.\" An $AMZN-$JCP $JCPNQ deal could reinvent retail real estate https://www.spglobal.com/m...   \n",
       "157712                                                                                                    $ROKU market up 500 pts but roku is down. so what happens if we have one of those lunchtime fades? watching to see if we have a sudden air pocket. $TSLA $NFLX $UNH $AMZN $GOOGL $SPY   \n",
       "80012                                                                                                                                                                                   Join @RobinhoodApp and we'll both get a stock like $AAPL, $F, or $S for free. Make sure to use my link.   \n",
       "45997                                                                                                                                                                                                                                                       $SPY $AAPL $MSFT $TLT Cash is trash   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                 nltk_lemma_pos  \\\n",
       "145314                                                                                        [(Action, n), (member, n), (wonder, v), (Jimmy, n), (Chill, n), (think, v), (strength, n), (share, n), (Friday, n), (hold, v), (great, a), (red, a), (tape, n), (Sign, n), (thing, n), (come, v)]   \n",
       "214230  [(quest, a), (grow, a), (real, a), (estate, n), (footprint, n), (resolve, n), (endure, v), (last, a), (mile, a), (delivery, n), (problem, n), (may, ), (lead, v), (troubled, a), (corner, n), (retail, a), (real, a), (estate, n), (â€”, n), (department, n), (store, n), (An, ), (dea...   \n",
       "157712                                                                                                                                             [(market, n), (pt, n), (roku, v), (happen, v), (one, ), (lunchtime, n), (fade, v), (watch, v), (see, v), (sudden, a), (air, n), (pocket, n)]   \n",
       "80012                                                                                                                                                                                         [(Join, n), (get, v), (stock, n), (like, ), (free, a), (Make, n), (sure, n), (use, n), (link, n)]   \n",
       "45997                                                                                                                                                                                                                                                                   [(Cash, n), (trash, n)]   \n",
       "\n",
       "                                                                                                                                                                                                              nltk_lemma  \n",
       "145314                                                                                                 [Action, member, wonder, Jimmy, Chill, think, strength, share, Friday, hold, great, red, tape, Sign, thing, come]  \n",
       "214230  [quest, grow, real, estate, footprint, resolve, endure, last, mile, delivery, problem, may, lead, troubled, corner, retail, real, estate, â€”, department, store, An, deal, could, reinvent, retail, real, estate]  \n",
       "157712                                                                                                                                 [market, pt, roku, happen, one, lunchtime, fade, watch, see, sudden, air, pocket]  \n",
       "80012                                                                                                                                                              [Join, get, stock, like, free, Make, sure, use, link]  \n",
       "45997                                                                                                                                                                                                      [Cash, trash]  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text[['text','nltk_lemma_pos','nltk_lemma']].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spell check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to eliminate double counting same words, you can also implement a spell checker \n",
    "https://medium.com/@thomasdecaux/build-a-spell-checker-with-word2vec-data-with-python-5438a9343afd\n",
    "\n",
    "smpl = df_text.loc[:1000,['text','spacy_transcript']]\n",
    "\n",
    "from textblob import TextBlob\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "def get_ner(text):\n",
    "    doc = nlp(text)\n",
    "    ner_list = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    return ner_list\n",
    "\n",
    "def spell_correction(text):\n",
    "    b = TextBlob(text)\n",
    "    return str(b.correct())\n",
    "\n",
    "def spell_checker(text):\n",
    "    spell = SpellChecker()\n",
    "    text = text.split()\n",
    "    un_words = spell.unknown(text)\n",
    "    new_text = ' '.join([spell.correction(word) if word in un_words else word for word in text])\n",
    "    return new_text\n",
    "\n",
    "%%time\n",
    "smpl['NER'] = smpl.loc[:,'spacy_transcript'].apply(get_ner)\n",
    "\n",
    "%%time\n",
    "smpl['spell_checked'] = smpl.loc[:,'spacy_transcript'].apply(spell_correction)\n",
    "\n",
    "%%time\n",
    "smpl['spell_checked_spellchecker'] = smpl.loc[:,'spacy_transcript'].apply(spell_checker)\n",
    "\n",
    "smpl[smpl.spacy_transcript != smpl.spell_checked_spellchecker].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_text shape: (417476, 9)\n",
      "df_rest shape: (417476, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"df_text shape:\", df_text.shape)\n",
    "print(\"df_rest shape:\", df_rest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_text,df_rest], axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape: (417476, 21)\n"
     ]
    }
   ],
   "source": [
    "print(\"df shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save file\n",
    "current_time = str(datetime.now().strftime(\"%H%M%S\"))\n",
    "df.to_pickle(r\"c:\\Users\\jaromir\\OneDrive\\UoM\\100_Disertation\\02_SrcData\\05_PreProcessed\\processed_tweets_\"+current_time+\".pkl\")\n",
    "stock_prices.to_pickle(r\"c:\\Users\\jaromir\\OneDrive\\UoM\\100_Disertation\\02_SrcData\\05_PreProcessed\\stock_prices_\"+current_time+\".pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "disProject",
   "language": "python",
   "name": "disproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
