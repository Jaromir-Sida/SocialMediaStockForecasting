{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set custom options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth',280)\n",
    "pd.set_option('display.html.use_mathjax', False)\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = r'c:\\Users\\jaromir\\OneDrive\\UoM\\100_Disertation\\02_SrcData\\05_PreProcessed'\n",
    "\n",
    "filenames = glob(src_path+'\\*.pkl')\n",
    "\n",
    "tweets = pd.read_pickle(filenames[0])\n",
    "stock_prices = pd.read_pickle(filenames[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(417476, 21)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = r'c:\\Users\\jaromir\\OneDrive\\UoM\\100_Disertation\\02_SrcData\\97_LabelledTweets'\n",
    "filenames = glob(src_path+'\\*.csv')\n",
    "labels = pd.read_csv(filenames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>Column2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Some top bullish flow we caught today $TSLA $VXX $AAPL $ZM $BA #stocks #optionsflow #options</td>\n",
       "      <td>1271212964503310000</td>\n",
       "      <td>6/12/2020 0:49</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Join us for Daily Powerful Watchlist, Swing &amp; Day Option Trading Alerts Paypal monthly link in bio, $134.99 DM for biweekly link $74.99 $fb $aapl $amzn $nflx $googl $bidu $roku $spy $amd $nvda $tsla $ba $baba $shop #trading</td>\n",
       "      <td>1230543208410730000</td>\n",
       "      <td>2/20/2020 18:22</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>$AMZN $AAPL down tomorrow? Trying to Shock Stocks With Emergency Cuts Usually Falls Short</td>\n",
       "      <td>1234976737114540000</td>\n",
       "      <td>3/3/2020 23:59</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Barron's Picks And Pans: Roundtable Picks, Airline And Oil Stocks, And More $LUV $DAL $UAL $CCL $LSB $MRK $AAPL $AMZN $BMY</td>\n",
       "      <td>1238951790864780000</td>\n",
       "      <td>3/14/2020 23:15</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Apple Confirms Redesigned Maps App Has Rolled Out to All Users Across United States http://dlvr.it/RP4HQP $AAPL</td>\n",
       "      <td>1222970881795740000</td>\n",
       "      <td>1/30/2020 20:52</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column1  \\\n",
       "0        0   \n",
       "1        1   \n",
       "2        2   \n",
       "3        3   \n",
       "4        4   \n",
       "\n",
       "                                                                                                                                                                                                                              text  \\\n",
       "0                                                                                                                                     Some top bullish flow we caught today $TSLA $VXX $AAPL $ZM $BA #stocks #optionsflow #options   \n",
       "1  Join us for Daily Powerful Watchlist, Swing & Day Option Trading Alerts Paypal monthly link in bio, $134.99 DM for biweekly link $74.99 $fb $aapl $amzn $nflx $googl $bidu $roku $spy $amd $nvda $tsla $ba $baba $shop #trading   \n",
       "2                                                                                                                                       $AMZN $AAPL down tomorrow? Trying to Shock Stocks With Emergency Cuts Usually Falls Short    \n",
       "3                                                                                                       Barron's Picks And Pans: Roundtable Picks, Airline And Oil Stocks, And More $LUV $DAL $UAL $CCL $LSB $MRK $AAPL $AMZN $BMY   \n",
       "4                                                                                                                 Apple Confirms Redesigned Maps App Has Rolled Out to All Users Across United States http://dlvr.it/RP4HQP $AAPL    \n",
       "\n",
       "                    id             date ticker  Column2  \n",
       "0  1271212964503310000   6/12/2020 0:49   AAPL      1.0  \n",
       "1  1230543208410730000  2/20/2020 18:22   AAPL      0.0  \n",
       "2  1234976737114540000   3/3/2020 23:59   AAPL     -1.0  \n",
       "3  1238951790864780000  3/14/2020 23:15   AAPL      0.0  \n",
       "4  1222970881795740000  1/30/2020 20:52   AAPL      0.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set tweets ID as index\n",
    "labels.set_index('id', drop=True, inplace=True)\n",
    "\n",
    "# drop original index\n",
    "labels.drop('Column1', axis= 1,inplace=True)\n",
    "\n",
    "# rename columns\n",
    "labels.columns = ['text','date','ticker','score']\n",
    "\n",
    "# drop rows with no class\n",
    "labels.dropna(axis=0,inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(566, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticker\n",
       "AAPL    50\n",
       "AMZN    26\n",
       "BABA    36\n",
       "DLT     19\n",
       "GILD    46\n",
       "HLT     56\n",
       "JNJ     41\n",
       "MAR     56\n",
       "MCD     56\n",
       "MSFT    53\n",
       "QSR     67\n",
       "UAL     60\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.groupby('ticker').score.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.67 s\n",
      "Parser   : 104 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tweets.loc[:,'spacy_text'] = tweets.loc[:,'spacy_lemma'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 709 ms\n",
      "Compiler : 287 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tweets.loc[:,'nltk_text'] = tweets.loc[:,'nltk_lemma'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fdist(df, attribute):\n",
    "    ticker_words = df.loc[:,attribute].str.cat(sep=' ')\n",
    "    fdist = FreqDist(ticker_words.split(\" \"))\n",
    "    return fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fdist_spacy = create_fdist(tweets,'spacy_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fdist_nltk = create_fdist(tweets,'nltk_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_words(fdist):\n",
    "    length = 0\n",
    "    output_list = []\n",
    "    for key, value in fdist:\n",
    "        if length < 5000:\n",
    "            if len(key) > 1:\n",
    "                output_list.append(key.lower())\n",
    "                length += 1\n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 163 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "spacy_most_common = most_common_words(fdist_spacy.most_common(6000))\n",
    "nltk_most_common = most_common_words(fdist_nltk.most_common(6000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ----------------- For improvement --------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. handling imbalanced classes\n",
    "https://medium.com/vickdata/detecting-hate-speech-in-tweets-natural-language-processing-in-python-for-beginners-4e591952223\n",
    "  \n",
    "1. Pipelines for multiple different classifiers\n",
    "https://medium.com/vickdata/a-simple-guide-to-scikit-learn-pipelines-4ac0d974bdcf\n",
    "  \n",
    "1. Improve lexicon based method by using only word formt he lexicon with the most extreme sentiment value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Lexicon-based sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"c:\\Users\\jaromir\\OneDrive\\UoM\\100_Disertation\\02_SrcData\\99_SentiWord\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiwords = pd.read_csv(path+\"\\\\SentiWords_1.1.txt\", encoding='utf-8', sep='\\t', skiprows=range(1,25,1), header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lemma(text):\n",
    "    return text.split('#')[0]\n",
    "\n",
    "def extract_pos(text):\n",
    "    return text.split('#')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 152 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentiwords.loc[:,'lemma'] = sentiwords.iloc[:,0].apply(extract_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 104 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentiwords.loc[:,'pos'] = sentiwords.iloc[:,0].apply(extract_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiwords = sentiwords.loc[:,['lemma','pos','prior_polarity_score']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a', 'n', 'r', 'v'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adjectives, nouns, verbs and adverbs\n",
    "sentiwords.pos.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiwords.loc[:,'nltk_common'] = 0\n",
    "sentiwords.loc[:,'nltk_common'].mask(sentiwords.lemma.isin(nltk_most_common), 1 , inplace= True)\n",
    "\n",
    "sentiwords.loc[:,'spacy_common'] = 0\n",
    "sentiwords.loc[:,'spacy_common'].mask(sentiwords.lemma.isin(spacy_most_common), 1 , inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiwords_nltk = sentiwords[sentiwords.nltk_common == 1]\n",
    "sentiwords_spacy = sentiwords[sentiwords.spacy_common == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiwords_spacy_idx = sentiwords_spacy.set_index(['lemma','pos'])\n",
    "sentiwords_nltk_idx = sentiwords_nltk.set_index(['lemma','pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_sentiment_value(list_of_tuples, lexicon):\n",
    "    score = 0\n",
    "    for tup in list_of_tuples:\n",
    "        try:\n",
    "            score = lexicon.loc[(tup[0],tup[1]),'prior_polarity_score']\n",
    "            score += score\n",
    "        except:\n",
    "            pass\n",
    "    return score\n",
    "\n",
    "# old, slow version, it is much faster to search through index than through regular attribute\n",
    "#def assign_sentiment_value(list_of_tuples, lexicon):\n",
    "#    res = 0\n",
    "#    for tup in list_of_tuples:\n",
    "#         idx = lexicon[(lexicon.lemma == tup[0]) & (lexicon.pos == tup[1])].index.values\n",
    "#         if len(idx) > 0:\n",
    "#             res = lexicon.loc[idx,'prior_polarity_score'].values[0]\n",
    "#             res += res\n",
    "#     return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tweets.loc[:,'nltk_lex'] = tweets.loc[:,'nltk_lemma_pos'].apply(assign_sentiment_value, args=[sentiwords_nltk_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tweets.loc[:,'spacy_lex'] = tweets.loc[:,'spacy_lemma_pos'].apply(assign_sentiment_value, args=[sentiwords_spacy_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>nltk_lex</th>\n",
       "      <th>spacy_lex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>345215</th>\n",
       "      <td>Stay ahead with Nasdaq 100 news, views &amp; analysis $MSFT $AAPL $GOOG http://www.cityfalcon.com/watchlists?name=Nasdaq%20Tracker&amp;amp;utm_campaign=T_AT</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32838</th>\n",
       "      <td>$aapl virus proving to be bullish for this company. 🦠 $spy $spx $qqq $dia $iwm</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50039</th>\n",
       "      <td>Can you get CoronaVirus from iPhone 11 at Apple Store? The screens look so 'high touched'. $AAPL</td>\n",
       "      <td>0.49462</td>\n",
       "      <td>0.91930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174342</th>\n",
       "      <td>FED Powell Economy Ready to BOOM Again! $AMZN $DIA $SPY $QQQ</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.81486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5720</th>\n",
       "      <td>Jeremy Siegel worries the hot 2020 stock market could collapse like it did in February 2018 https://www.cnbc.com/2020/01/09/jeremy-siegel-worries-the-hot-2020-market-may-fall-like-february-2018.html $SPY $QQQ $DJIA $DIA $GLD $SLV #stockmarket #investing #finance #stocks #gold...</td>\n",
       "      <td>-0.81654</td>\n",
       "      <td>-0.81654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170841</th>\n",
       "      <td>$SONM Launches New Product That Could Help Stop Spread Of #Covid19. Low-Float #Nasdaq Listed w/ +1,750% Upside! $bynd $tsla $csco $codx $regn $ba $wmt $tdoc $amzn $twtr $fb $googl $nflx $grub $sbux $zm $mgm $penn $vvus $crm $aal $btc $abt $msft $amrn https://financialnews.med...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62994</th>\n",
       "      <td>\"Rush Rally 3' Just Got a Big Update Adding a New Classic Cars Expansion IAP, Updated Graphics for All Cars, and More http://dlvr.it/RSvWSJ $AAPL</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149550</th>\n",
       "      <td>LMAO That was hilarious, @MikeBloomberg said \"any jackass can knock down a barn door. It takes a good carpenter to build a barn\" $NFLX $MSFT $TSLA $SPY $AAPL #stocks #MAGA $TGT $SHOP $JPM $BA $AMZN $GE $NIO $CHK $NOK $AMD $F $BAC $EEM $SDC $EFA $XLP $XLE $CSCO $QQQ $UBER $XOM $S</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404159</th>\n",
       "      <td>Beautiful. God I have loved $UAL this week.</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347239</th>\n",
       "      <td>Thurs (2/27/20) gap down highest % below OR 30-min low and trading range $BLDP $TSLA $PPL $WPX $NLY $MRVL $INTC $MSFT $COP $MET $COG $AAPL $IBM $XOM $USB $SIRI $FITB $MPC $BRK.B $BHC $O $CHNG $CVS $AXP $RDS.B $KEY $CLF $DOW $C</td>\n",
       "      <td>-0.00478</td>\n",
       "      <td>-0.00478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                           text  \\\n",
       "345215                                                                                                                                     Stay ahead with Nasdaq 100 news, views & analysis $MSFT $AAPL $GOOG http://www.cityfalcon.com/watchlists?name=Nasdaq%20Tracker&amp;utm_campaign=T_AT   \n",
       "32838                                                                                                                                                                                                            $aapl virus proving to be bullish for this company. 🦠 $spy $spx $qqq $dia $iwm   \n",
       "50039                                                                                                                                                                                         Can you get CoronaVirus from iPhone 11 at Apple Store? The screens look so 'high touched'. $AAPL    \n",
       "174342                                                                                                                                                                                                                             FED Powell Economy Ready to BOOM Again! $AMZN $DIA $SPY $QQQ   \n",
       "5720    Jeremy Siegel worries the hot 2020 stock market could collapse like it did in February 2018 https://www.cnbc.com/2020/01/09/jeremy-siegel-worries-the-hot-2020-market-may-fall-like-february-2018.html $SPY $QQQ $DJIA $DIA $GLD $SLV #stockmarket #investing #finance #stocks #gold...   \n",
       "170841  $SONM Launches New Product That Could Help Stop Spread Of #Covid19. Low-Float #Nasdaq Listed w/ +1,750% Upside! $bynd $tsla $csco $codx $regn $ba $wmt $tdoc $amzn $twtr $fb $googl $nflx $grub $sbux $zm $mgm $penn $vvus $crm $aal $btc $abt $msft $amrn https://financialnews.med...   \n",
       "62994                                                                                                                                         \"Rush Rally 3' Just Got a Big Update Adding a New Classic Cars Expansion IAP, Updated Graphics for All Cars, and More http://dlvr.it/RSvWSJ $AAPL   \n",
       "149550  LMAO That was hilarious, @MikeBloomberg said \"any jackass can knock down a barn door. It takes a good carpenter to build a barn\" $NFLX $MSFT $TSLA $SPY $AAPL #stocks #MAGA $TGT $SHOP $JPM $BA $AMZN $GE $NIO $CHK $NOK $AMD $F $BAC $EEM $SDC $EFA $XLP $XLE $CSCO $QQQ $UBER $XOM $S   \n",
       "404159                                                                                                                                                                                                                                              Beautiful. God I have loved $UAL this week.   \n",
       "347239                                                       Thurs (2/27/20) gap down highest % below OR 30-min low and trading range $BLDP $TSLA $PPL $WPX $NLY $MRVL $INTC $MSFT $COP $MET $COG $AAPL $IBM $XOM $USB $SIRI $FITB $MPC $BRK.B $BHC $O $CHNG $CVS $AXP $RDS.B $KEY $CLF $DOW $C   \n",
       "\n",
       "        nltk_lex  spacy_lex  \n",
       "345215   0.00000    0.00000  \n",
       "32838    0.00000    0.00000  \n",
       "50039    0.49462    0.91930  \n",
       "174342   0.00000    0.81486  \n",
       "5720    -0.81654   -0.81654  \n",
       "170841   0.00000    0.00000  \n",
       "62994    0.00000    0.00000  \n",
       "149550   0.00000    0.00000  \n",
       "404159   0.00000    0.00000  \n",
       "347239  -0.00478   -0.00478  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.loc[:,['text','nltk_lex','spacy_lex']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save file\n",
    "current_time = str(datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
    "tweets.to_pickle(r\"c:\\Users\\jaromir\\OneDrive\\UoM\\100_Disertation\\02_SrcData\\06_SentLabelled\\SentimentLabels1_\"+current_time+\".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Distant supervision using emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "#src_path = r'c:\\Users\\jaromir\\OneDrive\\UoM\\100_Disertation\\02_SrcData\\06_SentLabelled'\n",
    "#filenames = glob(src_path+'\\*.pkl')\n",
    "#tweets = pd.read_pickle(filenames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import operator\n",
    "import re\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_path = r\"c:\\Users\\jaromir\\OneDrive\\UoM\\100_Disertation\\02_SrcData\\98_Emoji_Sentiment\"\n",
    "df_emoji = pd.read_csv(emo_path+\"\\\\Emoji_Sentiment_Data_v1.0.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emoji['sent_score'] = (df_emoji.Positive - df_emoji.Negative) / df_emoji.Occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_with_emojis = tweets.loc[tweets.emoji != '',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_known_emojis(emoji_str):\n",
    "\n",
    "    em_split_emoji = emoji.get_emoji_regexp().split(emoji_str)\n",
    "    em_split_whitespace = [substr.split() for substr in em_split_emoji]\n",
    "    em_split = functools.reduce(operator.concat, em_split_whitespace)\n",
    "    \n",
    "    known_emojis = [emo for emo in em_split if emo in df_emoji['Emoji'].values]\n",
    "    return known_emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaromir\\Anaconda3\\envs\\disProject\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "tweets_with_emojis['emoji_list'] = tweets_with_emojis.loc[:,'emoji'].apply(filter_known_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all lines where emojis are not known\n",
    "tweets_with_emojis = tweets_with_emojis[tweets_with_emojis['emoji_list'].map(lambda d: len(d)) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emoji</th>\n",
       "      <th>emoji_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>🎀🏇🏇</td>\n",
       "      <td>[🎀, 🏇, 🏇]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>👉</td>\n",
       "      <td>[👉]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>🏆🇺🇸</td>\n",
       "      <td>[🏆]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>⬆</td>\n",
       "      <td>[⬆]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>🚔🚔🚔📊</td>\n",
       "      <td>[🚔, 🚔, 🚔]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417413</th>\n",
       "      <td>✈👨✈👩✈</td>\n",
       "      <td>[✈, 👨, ✈, 👩, ✈]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417432</th>\n",
       "      <td>🤦🏻♂</td>\n",
       "      <td>[♂]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417433</th>\n",
       "      <td>🥇🔽▪🥈🔽▪🥉🔽▪➡</td>\n",
       "      <td>[▪, ▪, ▪, ➡]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417457</th>\n",
       "      <td>🖊⛽🛢🎰✈✈⬇</td>\n",
       "      <td>[⛽, 🎰, ✈, ✈, ⬇]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417470</th>\n",
       "      <td>😱👍</td>\n",
       "      <td>[😱, 👍]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37473 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             emoji       emoji_list\n",
       "30             🎀🏇🏇        [🎀, 🏇, 🏇]\n",
       "39               👉              [👉]\n",
       "51             🏆🇺🇸              [🏆]\n",
       "53               ⬆              [⬆]\n",
       "86            🚔🚔🚔📊        [🚔, 🚔, 🚔]\n",
       "...            ...              ...\n",
       "417413       ✈👨✈👩✈  [✈, 👨, ✈, 👩, ✈]\n",
       "417432         🤦🏻♂              [♂]\n",
       "417433  🥇🔽▪🥈🔽▪🥉🔽▪➡     [▪, ▪, ▪, ➡]\n",
       "417457     🖊⛽🛢🎰✈✈⬇  [⛽, 🎰, ✈, ✈, ⬇]\n",
       "417470          😱👍           [😱, 👍]\n",
       "\n",
       "[37473 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_with_emojis.loc[:,['emoji','emoji_list']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emoji_sent(emoji_list):\n",
    "    total_score = 0\n",
    "    for emo in emoji_list:\n",
    "        score = df_emoji.loc[df_emoji['Emoji'] == emo,'sent_score'].values\n",
    "        if len(score) > 0: \n",
    "            total_score += score[0]            \n",
    "    if total_score > 0.25:\n",
    "        sent_score = 1\n",
    "    elif total_score >= -0.25 and total_score <= 0.25:\n",
    "        sent_score = 0\n",
    "    else:\n",
    "        sent_score = -1\n",
    "    return sent_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_with_emojis.loc[:,'emoji_score'] = tweets_with_emojis.loc[:,'emoji_list'].apply(get_emoji_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emoji_list</th>\n",
       "      <th>emoji_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125300</th>\n",
       "      <td>[👇, 💪, 👇]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220314</th>\n",
       "      <td>[➡]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140907</th>\n",
       "      <td>[💚, 💔, 💚, 💚, 💚, 💔, 💔, 💚]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318972</th>\n",
       "      <td>[👌, 👌, 👌, ❤]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355191</th>\n",
       "      <td>[🍞, 🍞, 🍞]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326870</th>\n",
       "      <td>[♀]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119547</th>\n",
       "      <td>[🔮]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378670</th>\n",
       "      <td>[😱, 😷, 📉]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180758</th>\n",
       "      <td>[💵, 🏪, 🏥]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162572</th>\n",
       "      <td>[🚂, 💰, 💰, 💰, 💰]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      emoji_list  emoji_score\n",
       "125300                 [👇, 💪, 👇]            1\n",
       "220314                       [➡]            0\n",
       "140907  [💚, 💔, 💚, 💚, 💚, 💔, 💔, 💚]            1\n",
       "318972              [👌, 👌, 👌, ❤]            1\n",
       "355191                 [🍞, 🍞, 🍞]            0\n",
       "326870                       [♀]            1\n",
       "119547                       [🔮]            1\n",
       "378670                 [😱, 😷, 📉]            1\n",
       "180758                 [💵, 🏪, 🏥]            1\n",
       "162572           [🚂, 💰, 💰, 💰, 💰]            1"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_with_emojis.loc[:,['emoji_list','emoji_score']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emoji_score\n",
       "-1      499\n",
       " 0     7418\n",
       " 1    29556\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_with_emojis.groupby('emoji_score').text.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### explenation of assumptions: \n",
    "https://towardsdatascience.com/sentiment-analysis-introduction-to-naive-bayes-algorithm-96831d77ac91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pprint import pprint\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_with_emojis.loc[:,'spacy_lemma_text'] = tweets_with_emojis.loc[:,'spacy_lemma'].apply(lambda x: ' '.join(x))\n",
    "tweets_with_emojis.loc[:,'nltk_lemma_text'] = tweets_with_emojis.loc[:,'nltk_lemma'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spacy_lemma_text</th>\n",
       "      <th>nltk_lemma_text</th>\n",
       "      <th>emoji_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79929</th>\n",
       "      <td>new video technology monopoly \" strong claim strong addition portfolio check new video find</td>\n",
       "      <td>NEW VIDEO Is ‘ technology monopoly ” strong enough claim strong addition portfolio Check new video find</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9646</th>\n",
       "      <td>today Update Reminder play contract time common Daily Goal today P l start Balance Account grow growth</td>\n",
       "      <td>Today ’ Update Reminder I play mostly contract time With common Daily Goal Today ’ P L Starting Balance Account Grows Growth</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106171</th>\n",
       "      <td>BOOM come Join pro daily Powerful Watchlist Swing amp Day Option Trading Alerts monthly link bio</td>\n",
       "      <td>BOOM Come Join The Pro For Daily Powerful Watchlist Swing amp Day Option Trading Alerts Monthly link bio</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268919</th>\n",
       "      <td>stock board Dow currently thing work treatment gold</td>\n",
       "      <td>As stock across board Dow currently thing work treatment Gold</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51978</th>\n",
       "      <td>today s Biggest Losers Tesla Inc » ️ percentage Apple Inc » ️ percentage Microsoft Corporation » ️ percentage ranking ️</td>\n",
       "      <td>Today Biggest Losers Tesla Inc » ️ percentage Apple Inc » ️ percentage Microsoft Corporation » ️ percentage Rankings ️</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387631</th>\n",
       "      <td>COMING SOON Sector Rotation Insights conversation monitor ️ ️ ️ ‍ ️ ️ meantime explore free content</td>\n",
       "      <td>COMING SOON Sector Rotation Insights across conversation monitor ️ ️ ️ ‍ ️ ️ In meantime explore free content</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411574</th>\n",
       "      <td>follow PART share tip profit market strategy work decision feel \" hurt y</td>\n",
       "      <td>Follow PART Re share tip profit market top strategy work well Decisions make make feel good ” almost always hurt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4053</th>\n",
       "      <td>video * MUST *</td>\n",
       "      <td>VIDEO * MUST SEE *</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32536</th>\n",
       "      <td>ready leg float curl trading perfectly buckle</td>\n",
       "      <td>ready next leg float Curling back trading perfectly Buckle</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256334</th>\n",
       "      <td>hr Volume Alert current volume average percentage average price percentage</td>\n",
       "      <td>hr Volume Alert current volume average percentage average Price percentage</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                               spacy_lemma_text  \\\n",
       "79929                               new video technology monopoly \" strong claim strong addition portfolio check new video find   \n",
       "9646                     today Update Reminder play contract time common Daily Goal today P l start Balance Account grow growth   \n",
       "106171                         BOOM come Join pro daily Powerful Watchlist Swing amp Day Option Trading Alerts monthly link bio   \n",
       "268919                                                                      stock board Dow currently thing work treatment gold   \n",
       "51978   today s Biggest Losers Tesla Inc » ️ percentage Apple Inc » ️ percentage Microsoft Corporation » ️ percentage ranking ️   \n",
       "387631                      COMING SOON Sector Rotation Insights conversation monitor ️ ️ ️ ‍ ️ ️ meantime explore free content   \n",
       "411574                                                 follow PART share tip profit market strategy work decision feel \" hurt y   \n",
       "4053                                                                                                             video * MUST *   \n",
       "32536                                                                             ready leg float curl trading perfectly buckle   \n",
       "256334                                               hr Volume Alert current volume average percentage average price percentage   \n",
       "\n",
       "                                                                                                                     nltk_lemma_text  \\\n",
       "79929                        NEW VIDEO Is ‘ technology monopoly ” strong enough claim strong addition portfolio Check new video find   \n",
       "9646    Today ’ Update Reminder I play mostly contract time With common Daily Goal Today ’ P L Starting Balance Account Grows Growth   \n",
       "106171                      BOOM Come Join The Pro For Daily Powerful Watchlist Swing amp Day Option Trading Alerts Monthly link bio   \n",
       "268919                                                                 As stock across board Dow currently thing work treatment Gold   \n",
       "51978         Today Biggest Losers Tesla Inc » ️ percentage Apple Inc » ️ percentage Microsoft Corporation » ️ percentage Rankings ️   \n",
       "387631                 COMING SOON Sector Rotation Insights across conversation monitor ️ ️ ️ ‍ ️ ️ In meantime explore free content   \n",
       "411574              Follow PART Re share tip profit market top strategy work well Decisions make make feel good ” almost always hurt   \n",
       "4053                                                                                                              VIDEO * MUST SEE *   \n",
       "32536                                                                     ready next leg float Curling back trading perfectly Buckle   \n",
       "256334                                                    hr Volume Alert current volume average percentage average Price percentage   \n",
       "\n",
       "        emoji_score  \n",
       "79929             1  \n",
       "9646              1  \n",
       "106171            1  \n",
       "268919            1  \n",
       "51978             1  \n",
       "387631            1  \n",
       "411574            1  \n",
       "4053              1  \n",
       "32536             1  \n",
       "256334            1  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_with_emojis.loc[:,['spacy_lemma_text','nltk_lemma_text','emoji_score']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CountVectorizer object\n",
    "vectorizer = CountVectorizer(lowercase=True, strip_accents='unicode', ngram_range=(1,1))\n",
    "\n",
    "# Generate matrix of word vectors\n",
    "bow_spacy_v = vectorizer.fit_transform(tweets_with_emojis.spacy_lemma_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_tfidf = TfidfVectorizer(lowercase=True, strip_accents='unicode', ngram_range=(1,1))\n",
    "\n",
    "# Generate matrix of word vectors\n",
    "bow_spacy_tfidf = vectorizer_tfidf.fit_transform(tweets_with_emojis.spacy_lemma_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_matrix = bow_spacy_v\n",
    "train_X, test_X, train_y, test_y = train_test_split(bow_matrix,\n",
    "                                                    tweets_with_emojis['emoji_score'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=tweets_with_emojis['emoji_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* average=micro says the function to compute f1 by considering total true positives, false negatives and false positives (no matter of the prediction for each label in the dataset)\n",
    "* average=macro says the function to compute f1 for each label, and returns the average without considering the proportion for each label in the dataset.\n",
    "* average=weighted says the function to compute f1 for each label, and returns the average considering the proportion for each label in the dataset.\n",
    "* average=samples says the function to compute f1 for each instance, and returns the average. Use it for multilabel classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNB = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = ['precision_samples', 'recall_samples', 'f1_samples']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KFold/StratifiedKFold cross validation with 3 folds (the default)\n",
    "# applying the classifier pipeline to the feature and target data\n",
    "scores_spacy_v = cross_validate(MNB, train_X, train_y, cv=5, scoring = 'f1_micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7528522434472579"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_spacy_v['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_spacy_tfidf = cross_val_score(MNB, train_X, train_y, cv=5, scoring = 'f1_micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75283522, 0.75100067, 0.75016678, 0.75095913, 0.75929942])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_spacy_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75 (+/- 0.01)\n",
      "Accuracy: 0.75 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_spacy_v['test_score'].mean(), scores_spacy_v['test_score'].std() * 2))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_spacy_tfidf.mean(), scores_spacy_tfidf.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch for best parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/tutorial/statistical_inference/putting_together.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(tweets_with_emojis['spacy_lemma_text'],\n",
    "                                                    tweets_with_emojis['emoji_score'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=tweets_with_emojis['emoji_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncommenting more parameters will give better exploring power but will\n",
    "# increase processing time in a combinatorial way\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__max_features': (None, 5000, 10000, 20000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__fit_prior': (True, False)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters:\n",
      "{'clf__fit_prior': (True, False),\n",
      " 'tfidf__norm': ('l1', 'l2'),\n",
      " 'tfidf__use_idf': (True, False),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0),\n",
      " 'vect__max_features': (None, 5000, 10000, 20000),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   45.0s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 960 out of 960 | elapsed:  3.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 231.095s\n",
      "\n",
      "Best score: 0.770\n",
      "Best parameters set:\n",
      "\tclf__fit_prior: True\n",
      "\ttfidf__norm: 'l2'\n",
      "\ttfidf__use_idf: True\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__max_features: 20000\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "# find the best parameters for both the feature extraction and the\n",
    "# classifier\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "grid_search.fit(train_X, train_y)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make prediction with NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(max_df=0.5, max_features = 20000, ngram_range = (1, 2))),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    ('clf', MultinomialNB(fit_prior = True)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tweets_with_emojis['spacy_lemma_text']\n",
    "y = tweets_with_emojis['emoji_score']\n",
    "X_full = tweets.loc[:,'spacy_lemma'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(max_df=0.5, max_features=20000,\n",
       "                                 ngram_range=(1, 2))),\n",
       "                ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.loc[:,'spacy_NB_sentiment'] = pipeline.predict(X_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'ticker', 'cashtags', 'emoji', 'filtered_text',\n",
       "       'spacy_lemma_pos', 'spacy_lemma', 'nltk_lemma', 'nltk_lemma_pos',\n",
       "       'username', 'to', 'retweets', 'favorites', 'replies', 'id', 'author_id',\n",
       "       'date', 'hashtags', 'mentions', 'urls', 'sentiment_collection_date',\n",
       "       'spacy_text', 'nltk_text', 'spacy_lex', 'nltk_lex',\n",
       "       'spacy_NB_sentiment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emoji</th>\n",
       "      <th>nltk_lex</th>\n",
       "      <th>spacy_lex</th>\n",
       "      <th>spacy_NB_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>224395</th>\n",
       "      <td>$TLRD had 634 stores of 1450 Locations open as of June 5th. $$$$Revenue $BA $TLRD $OAS $IDEX $DAL $CPE $SHIP $NCLH $ENLC $TTI $NFLX $M $RCL $HTZ $PRTY $QEP $OXY $NIO $NKLA $AAPL $LLEX $USO $MRO $MPC $KIRK $NVDA $AMD $MSFT $TSLA $FB $AMZN $INO $INTC $CSCO $CCL $AAL $ADBE</td>\n",
       "      <td></td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.64840</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318593</th>\n",
       "      <td>Jim Cramer advises investors not to get too optimistic over Moderna vaccine progress $MRNA $UAL $NCLH $MAR #coronavirus #COVID2019</td>\n",
       "      <td></td>\n",
       "      <td>0.79062</td>\n",
       "      <td>0.79062</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225316</th>\n",
       "      <td>$amzn too : 1626 to Cup N' handle target 2795-6</td>\n",
       "      <td></td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249016</th>\n",
       "      <td>2020-05-21 Short sale volume (not short interest) for $JD is 36%. http://shortvolumes.com/?t=JD $XLK 61% $LITB 64% $BABA 49%</td>\n",
       "      <td></td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5848</th>\n",
       "      <td>What time does limit down in $AAPL start today? Asking for a friend....at SNB</td>\n",
       "      <td></td>\n",
       "      <td>0.95374</td>\n",
       "      <td>0.95374</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18992</th>\n",
       "      <td>Really with this logic anyone profiting of gaming and video just as bad. Which includes $msft, $aapl, $goog, $amzn, and $nflx. Throw moral $dis in as well which has embraced sports gambling. Cigs are a carcinogen no matter what while social media can be used productively.</td>\n",
       "      <td></td>\n",
       "      <td>0.17258</td>\n",
       "      <td>0.17258</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69828</th>\n",
       "      <td>$SPY $DIA $AAPL $AMD $CCL $AAL Plot twist- get unemployment and buy stocks 😳👀</td>\n",
       "      <td>😳👀</td>\n",
       "      <td>0.19634</td>\n",
       "      <td>0.19634</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80663</th>\n",
       "      <td>Greg Abel to Share Stage With Warren Buffett at Annual Meeting $BRK.B $AAPL $WFC</td>\n",
       "      <td></td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.36242</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118021</th>\n",
       "      <td>$AAPL, $AMZN, $BRK/B, $HD, $LLY, $MA, $MCD, $MSFT, $NFLX, $NVDA, $PYPL, $TWLO, $UNP, V to Calls_For_Scalp_Very_Risky ($SL 20%).</td>\n",
       "      <td></td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318405</th>\n",
       "      <td>Equities Analysts Offer Predictions for Marriott International Inc’s Q3 2020 Earnings $MAR http://theenterpriseleader.com/?p=3138251</td>\n",
       "      <td></td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.25304</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                    text  \\\n",
       "224395    $TLRD had 634 stores of 1450 Locations open as of June 5th. $$$$Revenue $BA $TLRD $OAS $IDEX $DAL $CPE $SHIP $NCLH $ENLC $TTI $NFLX $M $RCL $HTZ $PRTY $QEP $OXY $NIO $NKLA $AAPL $LLEX $USO $MRO $MPC $KIRK $NVDA $AMD $MSFT $TSLA $FB $AMZN $INO $INTC $CSCO $CCL $AAL $ADBE   \n",
       "318593                                                                                                                                                Jim Cramer advises investors not to get too optimistic over Moderna vaccine progress $MRNA $UAL $NCLH $MAR #coronavirus #COVID2019   \n",
       "225316                                                                                                                                                                                                                                   $amzn too : 1626 to Cup N' handle target 2795-6   \n",
       "249016                                                                                                                                                      2020-05-21 Short sale volume (not short interest) for $JD is 36%. http://shortvolumes.com/?t=JD $XLK 61% $LITB 64% $BABA 49%   \n",
       "5848                                                                                                                                                                                                       What time does limit down in $AAPL start today? Asking for a friend....at SNB   \n",
       "18992   Really with this logic anyone profiting of gaming and video just as bad. Which includes $msft, $aapl, $goog, $amzn, and $nflx. Throw moral $dis in as well which has embraced sports gambling. Cigs are a carcinogen no matter what while social media can be used productively.   \n",
       "69828                                                                                                                                                                                                      $SPY $DIA $AAPL $AMD $CCL $AAL Plot twist- get unemployment and buy stocks 😳👀   \n",
       "80663                                                                                                                                                                                                   Greg Abel to Share Stage With Warren Buffett at Annual Meeting $BRK.B $AAPL $WFC   \n",
       "118021                                                                                                                                                   $AAPL, $AMZN, $BRK/B, $HD, $LLY, $MA, $MCD, $MSFT, $NFLX, $NVDA, $PYPL, $TWLO, $UNP, V to Calls_For_Scalp_Very_Risky ($SL 20%).   \n",
       "318405                                                                                                                                              Equities Analysts Offer Predictions for Marriott International Inc’s Q3 2020 Earnings $MAR http://theenterpriseleader.com/?p=3138251   \n",
       "\n",
       "       emoji  nltk_lex  spacy_lex  spacy_NB_sentiment  \n",
       "224395         0.00000    0.64840                   1  \n",
       "318593         0.79062    0.79062                   1  \n",
       "225316         0.00000    0.00000                   1  \n",
       "249016         0.00000    0.00000                   1  \n",
       "5848           0.95374    0.95374                   1  \n",
       "18992          0.17258    0.17258                   0  \n",
       "69828     😳👀   0.19634    0.19634                   1  \n",
       "80663          0.00000    0.36242                   1  \n",
       "118021         0.00000    0.00000                   1  \n",
       "318405         0.00000    0.25304                   1  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.loc[:,['text','emoji','nltk_lex','spacy_lex','spacy_NB_sentiment']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save file\n",
    "current_time = str(datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
    "tweets.to_pickle(r\"c:\\Users\\jaromir\\OneDrive\\UoM\\100_Disertation\\02_SrcData\\06_SentLabelled\\SentimentLabels2_\"+current_time+\".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vader sentiment\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "def get_VADER_polarity(text):\n",
    "    \"\"\"applies VADER analysis for polarity score\"\"\"\n",
    "    polarity_score =  sid.polarity_scores(text)\n",
    "    return polarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_compound_polarity(input_dict, polarity_score = 'compound'):\n",
    "    \"\"\"extract compount score from VADER polarity score\"\"\"\n",
    "    cmp_score = input_dict[polarity_score]\n",
    "    return cmp_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tweets.loc[:,'spacy_VADER_polarity'] = tweets.loc[:,'spacy_text'].apply(get_VADER_polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 705 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tweets.loc[:,'VADER_spacy_score'] = tweets.loc[:,'spacy_VADER_polarity'].apply(extract_compound_polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emoji</th>\n",
       "      <th>nltk_lex</th>\n",
       "      <th>spacy_lex</th>\n",
       "      <th>spacy_NB_sentiment</th>\n",
       "      <th>VADER_spacy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90918</th>\n",
       "      <td>Today Top Flow in S&amp;P 500 #SP500, Buy Flow and Sell Flow $NVDA $JPM $AMD $GILD $DHR $IBM $PG $CVX $COST $MU $AAPL $C $BA $GOOG $JNJ $PFE $MSFT $MRK $ABT $MA#stocks #StockMarket #Investment #investing https://apple.co/2XZuTYw</td>\n",
       "      <td></td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.15326</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113221</th>\n",
       "      <td>Some big players bought $136MM worth of $SPY at 302.15 around 11 am EST. $SPY $AAPL flagging up as well I think $SPY 302.71~300.47 will be the floor. Expecting a big gap up on Sunday enter a small starter $SPX 0615 3150c at 4.2 #daytrading #swingtrading #optiontrading #options</td>\n",
       "      <td></td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224993</th>\n",
       "      <td>On the surface it would seem $AMZN could be a buyer. Is the thought that Amazon reaps more rewards by letting $FSLY innovate on its own which in turn makes its AWS offering more compelling?</td>\n",
       "      <td></td>\n",
       "      <td>0.25304</td>\n",
       "      <td>0.25304</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401385</th>\n",
       "      <td>The Weekly Market Review | March 6, 2020 | $AAPL $TGT $UAL | https://youtu.be/bxQ4I0yOYh4 | #Stocks #TravelIndustry #Airlines #Investments #WallStreetNews</td>\n",
       "      <td></td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171810</th>\n",
       "      <td>HQ3 + SpacePort #HQ3 #SpacePort $AMZN</td>\n",
       "      <td></td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                         text  \\\n",
       "90918                                                        Today Top Flow in S&P 500 #SP500, Buy Flow and Sell Flow $NVDA $JPM $AMD $GILD $DHR $IBM $PG $CVX $COST $MU $AAPL $C $BA $GOOG $JNJ $PFE $MSFT $MRK $ABT $MA#stocks #StockMarket #Investment #investing https://apple.co/2XZuTYw   \n",
       "113221  Some big players bought $136MM worth of $SPY at 302.15 around 11 am EST. $SPY $AAPL flagging up as well I think $SPY 302.71~300.47 will be the floor. Expecting a big gap up on Sunday enter a small starter $SPX 0615 3150c at 4.2 #daytrading #swingtrading #optiontrading #options   \n",
       "224993                                                                                          On the surface it would seem $AMZN could be a buyer. Is the thought that Amazon reaps more rewards by letting $FSLY innovate on its own which in turn makes its AWS offering more compelling?   \n",
       "401385                                                                                                                             The Weekly Market Review | March 6, 2020 | $AAPL $TGT $UAL | https://youtu.be/bxQ4I0yOYh4 | #Stocks #TravelIndustry #Airlines #Investments #WallStreetNews   \n",
       "171810                                                                                                                                                                                                                                                 HQ3 + SpacePort #HQ3 #SpacePort $AMZN    \n",
       "\n",
       "       emoji  nltk_lex  spacy_lex  spacy_NB_sentiment  VADER_spacy_score  \n",
       "90918          0.00000    0.15326                   1             0.2023  \n",
       "113221         0.00000    0.00000                   1             0.2263  \n",
       "224993         0.25304    0.25304                   1             0.8591  \n",
       "401385         0.00000    0.00000                   1             0.0000  \n",
       "171810         0.00000    0.00000                   0             0.0000  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.loc[:,['text','emoji','nltk_lex','spacy_lex','spacy_NB_sentiment','VADER_spacy_score']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VADER_sentiment_classifier(vader_score):\n",
    "    if vader_score > 0.1 :\n",
    "        sentiment = 1\n",
    "    elif vader_score < -0.1:\n",
    "        sentiment = 0\n",
    "    else:\n",
    "        sentiment = -1\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 210 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tweets.loc[:,'VADER_spacy_score'] = tweets.loc[:,'VADER_spacy_score'].apply(VADER_sentiment_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emoji</th>\n",
       "      <th>nltk_lex</th>\n",
       "      <th>spacy_lex</th>\n",
       "      <th>spacy_NB_sentiment</th>\n",
       "      <th>VADER_spacy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128180</th>\n",
       "      <td>Join us for Daily Powerful Watchlist, Swing &amp; Day Option Trading Alerts Paypal monthly link in bio, $99.99 DM for biweekly link $59.99 $fb $aapl $amzn $nflx $googl $bidu $roku $spy $amd $nvda $tsla $ba $baba $shop #trading #OptionsTrading</td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130930</th>\n",
       "      <td>At breakeven now, if $AMZN cracks low of day looking ot cash in around 1883/84, that should be close to 100% on the 3 puts</td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248641</th>\n",
       "      <td>close $BABA IC 190/230 $5wings JUN $157db a $24 win over night, super small win, nearly a scratch, but by bye, don't want to be here @TraderNickyBAT @Tomunderwater @Tony_BATtista @TFMTrades @tastytradar #tastytrades</td>\n",
       "      <td></td>\n",
       "      <td>0.4917</td>\n",
       "      <td>0.49170</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7421</th>\n",
       "      <td>Weekly Stock Market Review: ✅ Week #3✅Stay Ahead Of The Curve: Top 10 Stock Picks For January 2020: http://messages.responder.co.il/4370841/ $AAPL $NVDA $MU $AMZN $FB $GOOGL $NFLX $SPY $QQQ $DIA $INTC $AMD $F $GOOG $BRK_B $GLD $SBUX $BA $VIX $CC $VAC $WIX #NASDAQ #Apple #trad...</td>\n",
       "      <td>✅✅</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.25856</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75977</th>\n",
       "      <td>$AAPL #Options Power and #Profile Update #OptionsTrading https://apple.co/2XZuTYw https://twitter.com/minteractapp/status/1252643349699280896?s=21</td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                           text  \\\n",
       "128180                                           Join us for Daily Powerful Watchlist, Swing & Day Option Trading Alerts Paypal monthly link in bio, $99.99 DM for biweekly link $59.99 $fb $aapl $amzn $nflx $googl $bidu $roku $spy $amd $nvda $tsla $ba $baba $shop #trading #OptionsTrading   \n",
       "130930                                                                                                                                                               At breakeven now, if $AMZN cracks low of day looking ot cash in around 1883/84, that should be close to 100% on the 3 puts   \n",
       "248641                                                                  close $BABA IC 190/230 $5wings JUN $157db a $24 win over night, super small win, nearly a scratch, but by bye, don't want to be here @TraderNickyBAT @Tomunderwater @Tony_BATtista @TFMTrades @tastytradar #tastytrades   \n",
       "7421    Weekly Stock Market Review: ✅ Week #3✅Stay Ahead Of The Curve: Top 10 Stock Picks For January 2020: http://messages.responder.co.il/4370841/ $AAPL $NVDA $MU $AMZN $FB $GOOGL $NFLX $SPY $QQQ $DIA $INTC $AMD $F $GOOG $BRK_B $GLD $SBUX $BA $VIX $CC $VAC $WIX #NASDAQ #Apple #trad...   \n",
       "75977                                                                                                                                        $AAPL #Options Power and #Profile Update #OptionsTrading https://apple.co/2XZuTYw https://twitter.com/minteractapp/status/1252643349699280896?s=21   \n",
       "\n",
       "       emoji  nltk_lex  spacy_lex  spacy_NB_sentiment  VADER_spacy_score  \n",
       "128180          0.0000    0.00000                   1                  1  \n",
       "130930          0.0000    0.00000                   1                  0  \n",
       "248641          0.4917    0.49170                   1                  1  \n",
       "7421      ✅✅    0.0000    0.25856                   1                  1  \n",
       "75977           0.0000    0.00000                   1                 -1  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.loc[:,['text','emoji','nltk_lex','spacy_lex','spacy_NB_sentiment','VADER_spacy_score']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save file\n",
    "current_time = str(datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
    "tweets.to_pickle(r\"c:\\Users\\jaromir\\OneDrive\\UoM\\100_Disertation\\02_SrcData\\06_SentLabelled\\SentimentLabels3_\"+current_time+\".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Teach on external labelled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative_tweets.json', 'positive_tweets.json', 'tweets.20150430-223406.json']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# http://www.nltk.org/howto/twitter.html\n",
    "from nltk.corpus import twitter_samples\n",
    "twitter_samples.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\jaromir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = all_words = nltk.FreqDist(movie_reviews.words()).most_common(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector = list(all_words)[:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_file_id = movie_reviews.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews_list = [(movie_reviews.words(file_id),category) for file_id in movie_reviews.fileids() for category in movie_reviews.categories(file_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_movie_reviews(list_of_tuples):\n",
    "    df = pd.DataFrame(columns=['text','score'])\n",
    "    \n",
    "    # text\n",
    "    text = [tup[0] for tup in list_of_tuples]\n",
    "    df['text'] = text\n",
    "    df.loc[:,'text'] = df.loc[:,'text'].apply(lambda x: ' '.join(x))\n",
    "    \n",
    "    # scores\n",
    "    scores = [1 if tup[1]=='pos' else 0 for tup in list_of_tuples]\n",
    "    df.loc[:,'score'] = scores\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews_df = format_movie_reviews(movie_reviews_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(movie_reviews_df['text'],\n",
    "                                                    movie_reviews_df['score'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=movie_reviews_df['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncommenting more parameters will give better exploring power but will\n",
    "# increase processing time in a combinatorial way\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__max_features': (None, 5000, 10000, 20000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__fit_prior': (True, False)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters:\n",
      "{'clf__fit_prior': (True, False),\n",
      " 'tfidf__norm': ('l1', 'l2'),\n",
      " 'tfidf__use_idf': (True, False),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0),\n",
      " 'vect__max_features': (None, 5000, 10000, 20000),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=-1)]: Done 960 out of 960 | elapsed: 17.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1074.542s\n",
      "\n",
      "Best score: 0.841\n",
      "Best parameters set:\n",
      "\tclf__fit_prior: True\n",
      "\ttfidf__norm: 'l2'\n",
      "\ttfidf__use_idf: True\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__max_features: 20000\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "# find the best parameters for both the feature extraction and the\n",
    "# classifier\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "grid_search.fit(train_X, train_y)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### making rpediction with NB learned on movie reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(max_df=0.5, max_features = 20000, ngram_range = (1, 2))),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    ('clf', MultinomialNB(fit_prior = True)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = movie_reviews_df['text']\n",
    "y = movie_reviews_df['score']\n",
    "X_full = tweets.spacy_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(max_df=0.5, max_features=20000,\n",
       "                                 ngram_range=(1, 2))),\n",
       "                ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.loc[:,'spacy_movie_NB_sentiment'] = pipeline.predict(X_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emoji</th>\n",
       "      <th>nltk_lex</th>\n",
       "      <th>spacy_lex</th>\n",
       "      <th>spacy_NB_sentiment</th>\n",
       "      <th>spacy_movie_NB_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>379315</th>\n",
       "      <td>$spy $spx $aapl $amzn $qqq $twtr $mrna $msft</td>\n",
       "      <td></td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119686</th>\n",
       "      <td>$AAPL hits new high on store closures. What a world.</td>\n",
       "      <td></td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193764</th>\n",
       "      <td>David Faber debating against likelihood of $AMZN buyout of $AMC. $AMC up 45% on buyout mentioned in Daily Mail report</td>\n",
       "      <td></td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266243</th>\n",
       "      <td>Also, if you are new to $GILD here's a background article on Finpedia for you https://finpedia.co/bin/Gilead%20Sciences/</td>\n",
       "      <td></td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211341</th>\n",
       "      <td>2 Cheap Technology Stocks to Buy Now $MSFT $QCOM Also $AAPL $AMZN $GOOG $FB</td>\n",
       "      <td></td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.94800</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44453</th>\n",
       "      <td>If you own $AAPL stock, now is the time to look at these three suppliers.</td>\n",
       "      <td></td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144133</th>\n",
       "      <td>Why didn’t $AMZN go w $TSLA $TSLAQ? They know it’s a piece of shit?</td>\n",
       "      <td></td>\n",
       "      <td>-0.54696</td>\n",
       "      <td>-0.54696</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409637</th>\n",
       "      <td>On Watch. $UAL $UAA $GIS $MAR $CAH $ON $BA $TSLA. Let the games begin!!!</td>\n",
       "      <td></td>\n",
       "      <td>0.80390</td>\n",
       "      <td>0.80390</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78829</th>\n",
       "      <td>Price gainers on Friday - $AZO $SHOP $W $ORLY $CMG $GWW $BYND $QDEL $ZM $TMO $SRPT $LTRPB $DXCM $CHK $MESO $TDOC $SIVB $TSA $HD $VICR $COHR $QURE $HUBS $TSCO $AAPL $RNG $WSO $RH $GBT $RGEN $EBS $MASI $PZZA $LAD $WWE $VEEV $MKTX $NXPI $CRWD $ANET $NVRO</td>\n",
       "      <td></td>\n",
       "      <td>0.16822</td>\n",
       "      <td>0.16822</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134662</th>\n",
       "      <td>Mozart trading system: https://profectussystems.autotradenow.com/details/85617966 $TQQQ $WOOF $XLP $QLD $IBB $HDV $CCI $GLD $EFX $CNP $IFF $TSLA $AMZN $MSFT $IBM $GOOGL $SPY</td>\n",
       "      <td></td>\n",
       "      <td>0.22130</td>\n",
       "      <td>0.22130</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                               text  \\\n",
       "379315                                                                                                                                                                                                                $spy $spx $aapl $amzn $qqq $twtr $mrna $msft    \n",
       "119686                                                                                                                                                                                                         $AAPL hits new high on store closures. What a world.   \n",
       "193764                                                                                                                                        David Faber debating against likelihood of $AMZN buyout of $AMC. $AMC up 45% on buyout mentioned in Daily Mail report   \n",
       "266243                                                                                                                                     Also, if you are new to $GILD here's a background article on Finpedia for you https://finpedia.co/bin/Gilead%20Sciences/   \n",
       "211341                                                                                                                                                                                  2 Cheap Technology Stocks to Buy Now $MSFT $QCOM Also $AAPL $AMZN $GOOG $FB   \n",
       "44453                                                                                                                                                                                    If you own $AAPL stock, now is the time to look at these three suppliers.    \n",
       "144133                                                                                                                                                                                          Why didn’t $AMZN go w $TSLA $TSLAQ? They know it’s a piece of shit?   \n",
       "409637                                                                                                                                                                                     On Watch. $UAL $UAA $GIS $MAR $CAH $ON $BA $TSLA. Let the games begin!!!   \n",
       "78829   Price gainers on Friday - $AZO $SHOP $W $ORLY $CMG $GWW $BYND $QDEL $ZM $TMO $SRPT $LTRPB $DXCM $CHK $MESO $TDOC $SIVB $TSA $HD $VICR $COHR $QURE $HUBS $TSCO $AAPL $RNG $WSO $RH $GBT $RGEN $EBS $MASI $PZZA $LAD $WWE $VEEV $MKTX $NXPI $CRWD $ANET $NVRO   \n",
       "134662                                                                                Mozart trading system: https://profectussystems.autotradenow.com/details/85617966 $TQQQ $WOOF $XLP $QLD $IBB $HDV $CCI $GLD $EFX $CNP $IFF $TSLA $AMZN $MSFT $IBM $GOOGL $SPY   \n",
       "\n",
       "       emoji  nltk_lex  spacy_lex  spacy_NB_sentiment  \\\n",
       "379315         0.00000    0.00000                   1   \n",
       "119686         0.00000    0.00000                   1   \n",
       "193764         0.00000    0.00000                   1   \n",
       "266243         0.00000    0.00000                   1   \n",
       "211341         0.00000    0.94800                   1   \n",
       "44453          0.00000    0.00000                   1   \n",
       "144133        -0.54696   -0.54696                   1   \n",
       "409637         0.80390    0.80390                   1   \n",
       "78829          0.16822    0.16822                   1   \n",
       "134662         0.22130    0.22130                   1   \n",
       "\n",
       "        spacy_movie_NB_sentiment  \n",
       "379315                         0  \n",
       "119686                         1  \n",
       "193764                         1  \n",
       "266243                         1  \n",
       "211341                         0  \n",
       "44453                          0  \n",
       "144133                         1  \n",
       "409637                         0  \n",
       "78829                          0  \n",
       "134662                         1  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.loc[:,['text','emoji','nltk_lex','spacy_lex','spacy_NB_sentiment','spacy_movie_NB_sentiment']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save file\n",
    "current_time = str(datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
    "tweets.to_pickle(r\"c:\\Users\\jaromir\\OneDrive\\UoM\\100_Disertation\\02_SrcData\\06_SentLabelled\\SentimentLabels4_\"+current_time+\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_cool_stuff():\n",
    "    \n",
    "    os.chdir(out_path)\n",
    "    \n",
    "    do_countdown(5)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    print(\"working ...\")\n",
    "    time.sleep(2)\n",
    "    print(\"The output is ready!\")\n",
    "    time.sleep(1)\n",
    "    os.system(\"START /MAX notepad.exe msg.txt\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Transfer-learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names()\n",
    "\n",
    "# Convert bow_matrix into a DataFrame\n",
    "bow_df = pd.DataFrame(bow_matrix.toarray())\n",
    "\n",
    "# Map the column names to vocabulary \n",
    "bow_df.columns = vectorizer.get_feature_names()\n",
    "\n",
    "# Print bow_df\n",
    "print(bow_df)\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(df['review'], df['sentiment'], test_size=0.5, random_state=42, stratify=df['sentiment'])\n",
    "\n",
    "# Generating ngrams\n",
    "vectorizer = CountVectorizer(ngram_range=(1,3))\n",
    "train_X = vectorizer.fit_transform(train_X)\n",
    "test_X = vectorizer.transform(test_X)\n",
    "\n",
    "## TF-IDF\n",
    "\n",
    "\n",
    "\n",
    "# Create CountVectorizer object\n",
    "vectorizer = TfidfVectorizer(lowercase=False)\n",
    "\n",
    "# Generate matrix of word vectors\n",
    "bow_matrix = vectorizer.fit_transform(df_text.text)\n",
    "\n",
    "# Print the shape of bow_matrix\n",
    "print(bow_matrix_lem.shape)\n",
    "\n",
    "# Remember, the value corresponding to the ith row and jth column of a similarity matrix \n",
    "# denotes the similarity score for the ith and jth vector.\n",
    "cosine_sim = linear_kernel(bow_matrix[:10000,:], bow_matrix[:10000,:])\n",
    "\n",
    "cosine_sim[0,:]\n",
    "\n",
    "def max_sim(row_idx ,cosine_sim_matrix):\n",
    "    # finds the index value of the \n",
    "    max_sim = np.argsort(cosine_sim_matrix[row_idx,:])[-2]\n",
    "    \n",
    "    print(df_text.loc[row_idx,'text'],\"\\n\")\n",
    "    print(df_text.loc[max_sim,'text'])\n",
    "\n",
    "df_text.loc[:,'text']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Spacy - Named entity recognition\n",
    "\n",
    "def find_persons(text):\n",
    "  # Create Doc object\n",
    "  doc = nlp(text)\n",
    "  \n",
    "  # Identify the persons\n",
    "  persons = [ent.text for ent in doc.ents if ent.label_ == 'PERSON']\n",
    "  \n",
    "  # Return persons\n",
    "  return persons\n",
    "\n",
    "print(find_persons(tc))\n",
    "\n",
    "df_text.loc[np.argsort(cosine_sim[1,:])[-2],'text']\n",
    "\n",
    "np.where(cosine_sim[0,:] == max_sim)\n",
    "\n",
    "np.argsort(cosine_sim[0,:])[-2]\n",
    "\n",
    "max_sim(3,cosine_sim)\n",
    "\n",
    "cosine_sim[0,:][np.argsort(cosine_sim[0,:]) == 998][0]\n",
    "\n",
    "df_text.loc[[0],'text']\n",
    "\n",
    "df_text.loc[[517],'text']\n",
    "\n",
    "## Embeddings\n",
    "\n",
    "import en_core_web_lg\n",
    "nlp_lg = en_core_web_lg.load()\n",
    "\n",
    "doc = nlp_lg(\"I am happy\")\n",
    "for token1 in doc:\n",
    "    for token2 in doc:\n",
    "        print(token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader.loc[:,'date'] = pd.to_datetime(vader.loc[:,'date']).dt.date\n",
    "\n",
    "vader_ts = vader[(vader.VADER_sentiment != 'N') & (vader.ticker == 'JPM')].groupby(['ticker','date']).mean()\n",
    "\n",
    "jpm_price = stock_price[stock_price.ticker == 'JPM']\n",
    "jpm_price.loc[:,'Date'] = pd.to_datetime(jpm_price.Date)\n",
    "jpm_price.set_index('Date', inplace=True)\n",
    "jpm_price = jpm_price['Adj Close']\n",
    "jpm_price.head()\n",
    "\n",
    "vader_ts.index = vader_ts.index.droplevel()\n",
    "\n",
    "vader_ts.head(3)\n",
    "\n",
    "sent_price = vader_ts.merge(jpm_price, left_index=True, right_index=True)\n",
    "\n",
    "x = sent_price.index\n",
    "y1 = sent_price.VADER_score\n",
    "y2 = sent_price['Adj Close']\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10,6))\n",
    "\n",
    "ax1.plot(x,y1, c='royalblue', label = 'VADER_score')\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(x,y2, c ='red', label = 'Stock price')\n",
    "\n",
    "ax1.set_xticklabels(x,rotation=30)\n",
    "ax1.set_title('JPM sentiment against stock price in time')\n",
    "fig.legend(bbox_to_anchor=(0.32, -0.2, 0.5, 0.5))\n",
    "plt.show()\n",
    "\n",
    "stock_price"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "disProject",
   "language": "python",
   "name": "disproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
